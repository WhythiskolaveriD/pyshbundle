{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to PySHbundle","text":"<p>PySHbundle: A Python implementation of MATLAB codes SHbundle</p> <ul> <li>Free software: GNU General Public License v3</li> <li>Documentation: https://mn5hk.github.io/pyshbundle</li> </ul>"},{"location":"#how-to-install","title":"How to install","text":"<p>We recommend using Mamba to install required packages  <code>conda create pysh</code> <code>conda activate pysh</code> <code>conda install -c conda-forge mamba</code> <code>mamba install -c conda-forge numpy pandas netCDF4 scipy xarray julian scipy geopandas matplotlib rasterio salem shapely</code> </p> <p>Convert SHbundle matlab codes to python Geodesy for Earth system science (GESS) research Group at ICWaR, IISc </p> <p>Currently we are upgrading (under process) the package to be implementable on binder.  </p>"},{"location":"#mathematics","title":"Mathematics","text":"<p>In this section, we present a mathematical representation of the spherical harmonics analysis. According to potential theory, the gravitational field of a body fulfils the Laplace equation \\(\\nabla^2\\phi = 0\\). Laplace's equation in spherical coordinates can be written as follows: </p> \\[\\begin{equation}     \\frac{1}{r^2}\\frac{\\partial}{\\partial r}\\bigg( r^2\\frac{\\partial \\phi}{\\partial r}\\bigg)       +     \\frac{1}{r^2\\sin\\vartheta}\\frac{\\partial}{\\partial \\vartheta}\\bigg(\\sin\\vartheta\\frac{\\partial \\phi}{\\partial \\vartheta}\\bigg)      +     \\frac{1}{r^2\\sin^2\\vartheta}\\frac{\\partial^2 \\phi}{\\partial \\lambda^2}     = 0 , \\end{equation}\\] <p>where  \\(\\phi\\) is the potential,  \\(r\\) is the radius,  \\(\\vartheta\\) is the co-latitude and  \\(\\lambda\\) is the longitude. </p> <p>We perform a separation of variables and insert \\(\\phi(r, \\vartheta, \\lambda) =f(r)g(\\vartheta)h(\\lambda)\\) into the Laplace equation to get three independent equations:</p> \\[\\begin{equation} r^2\\frac{d^2f}{dr^2}+2r\\frac{df}{dr} - n(n+1)f = 0, \\end{equation}\\] \\[\\begin{equation} \\frac{d^2g}{d\\vartheta^2} + \\frac{dg}{d\\vartheta}\\cot\\vartheta + \\bigg(  n(n+1) - \\frac{m^2}{\\sin^2\\vartheta}   \\bigg) g = 0 , \\end{equation}\\] \\[\\begin{equation} \\frac{d^2h}{d\\lambda^2} + m^2h = 0, \\end{equation}\\] <p>where \\(m\\) and \\(n\\) are the degree and order respectively. Solving \\((2), (3)\\) and \\((4)\\), we obtain: </p> \\[\\begin{equation} f(r) \\in \\{r^n, r^{-(n+1)}\\}, \\end{equation}\\] \\[\\begin{equation} g(\\vartheta) \\in \\{P_{n,m}(\\cos \\vartheta), Q_{n,m}(\\cos \\vartheta)\\} , \\end{equation}\\] <p>\\begin{equation} h(\\lambda) \\in {\\cos m\\lambda, \\sin m\\lambda}. \\end{equation}\\</p> <p>Thus, the Laplace equation's solution takes the following form: </p> \\[\\begin{equation} \\phi(r, \\vartheta, \\lambda) = \\sum_{n=0}^{\\infty} \\sum_{m=0}^{n}  \\alpha_{n,m} \\begin{Bmatrix} P_{n,m}(\\cos\\vartheta)\\\\ Q_{n,m}(\\cos\\vartheta)\\\\ \\end{Bmatrix} \\dot{\u2022} \\begin{Bmatrix} \\cos m\\lambda\\\\ \\sin m\\lambda\\\\ \\end{Bmatrix} \\dot{\u2022} \\begin{Bmatrix} r^n\\\\ r^{(n+1)}\\\\ \\end{Bmatrix} . \\end{equation}\\] <p>Solutions for \\(f(r)\\) and \\(h(\\lambda)\\) are fairly straightforward. Eq - (3) for \\(g(\\vartheta)\\) is in the form of a Legendre differential equation and its solutions are \\(P_{n,m}(\\cos \\vartheta)\\) and \\(Q_{n,m}(\\cos \\vartheta)\\), the associated Legendre functions of the first and second kind. We now apply two constraints to the solution:</p> <ul> <li>\\(\\phi \\rightarrow 0\\) when \\(r \\rightarrow \\infty\\),</li> <li>\\(\\phi\\) is limited on the sphere,</li> </ul> <p>which leads us to eliminate \\(Q_{n,m}(\\cos \\vartheta)\\) and \\(r^n\\).The \\(4\\pi\\) normalization of the Associated Legendre functions [8] is utilized in our package and is given by: </p> \\[\\begin{equation} \\bar{P}_{n,m}(\\cos\\vartheta) = P_{n,m}(\\cos\\vartheta)\\sqrt{(2-\\delta_{m0})(2n+1)\\frac{(n-m)!}{(n+m)!}}, \\end{equation}\\] <p>where \\(\\delta_{m0}\\) is the Kronecker delta function,</p> \\[\\begin{equation} P_{n,m}(t) = (1-t^2)^{\\frac{m}{2}}\\frac{d^mP_n(t)}{dt^m}, \\end{equation}\\] <p>and </p> \\[\\begin{equation} nP_n(t)=-(n-1)P_{n-2}(t) + (2n-1)tP_{n-1}(t). \\end{equation}\\] <p>Spherical harmonics are the angular portion of a set of solutions to Laplace's equation. They take into account \\(\\vartheta\\) and \\(\\lambda\\). They are functions modelled on the surface of a sphere, denoted by \\(Y_{n,m}(\\vartheta,\\lambda)\\). They are of three kinds: </p> <ul> <li>Zonal harmonics: \\(m=0\\) - they are only latitude dependent,</li> <li>Tesseral harmonics: \\(0 &lt; m &lt; n\\), and </li> <li>Sectorial harmonics: \\(m=n\\).</li> </ul> <p>Quantities like the gravitational potential, height of water column, gravity anomaly and so on are the functionals of the gravity field which are obtained by differentiating the potential \\(\\phi\\) with respect to the spherical coordinates. </p> <p>The gravitational potential anomaly \\(V\\) is given by:</p> \\[\\begin{equation}     V(r, \\vartheta, \\lambda) =      \\frac{GM}{r} \\sum_{n=0} ^{N_{max}} \\sum_{m=0} ^{n}      \\left(\\frac{R}{r}\\right) ^{n+1}     \\bar{P}_{n,m}(\\cos \\vartheta) [C_{n,m}\\cos m\\lambda+S_{n,m}\\sin m\\lambda]. \\end{equation}\\] <p>Here, \\(R\\) refers to the radius of the Earth, \\(\\bar{P}_ {n,m}\\) refers to the Associated Legendre functions with \\(4\\pi\\) normalization, \\(C_{lm}\\) and  \\(S_{lm}\\) refer to the spherical harmonic coefficients. Similarly, another functional, the change in surface mass density, is represented by:</p> \\[\\begin{equation}     \\Delta\\sigma(\\vartheta, \\lambda) =      \\frac{a\\rho_{ave}}{3}      \\sum_{n=0}^{N_{max}}\\sum_{m=0}^{n}      \\left(\\frac{R}{r}\\right)^{n+1}      \\bar{P}_{n,m}(\\cos\\vartheta)     \\frac{2n+1}{1+k_l}     [C_{n,m}\\cos m\\lambda + S_{n,m}\\sin m\\lambda], \\end{equation}\\] <p>where \\(\\rho_{ave}\\) refers to the average density of the Earth in \\(g/cm^3\\) and \\(k_n\\) refers to the load Love number of degree \\(n\\).</p>"},{"location":"#credits","title":"Credits","text":"<p>This package was created with Cookiecutter and the giswqs/pypackage project template.</p>"},{"location":"acknowledgement/","title":"Acknowledgement:","text":"<p>Please note that PySHbundle has adapted the following code packages, both licensed under GNU General Public License</p> <ol> <li> <p>SHbundle: https://www.gis.uni-stuttgart.de/en/research/downloads/shbundle/</p> </li> <li> <p>Downscaling GRACE Total Water Storage Change using Partial Least Squares Regression - https://springernature.figshare.com/collections/Downscaling_GRACE_Total_Water_Storage_Change_using_Partial_Least_Squares_Regression/5054564 </p> </li> </ol>"},{"location":"acknowledgement/#key-papers-referred","title":"Key Papers Referred:","text":"<ol> <li> <p>Vishwakarma, B. D., Horwath, M., Devaraju, B., Groh, A., &amp; Sneeuw, N. (2017).        A data\u2010driven approach for repairing the hydrological catchment signal damage        due to filtering of GRACE products. Water Resources Research,        53(11), 9824-9844. https://doi.org/10.1002/2017WR021150</p> </li> <li> <p>Vishwakarma, B. D., Zhang, J., &amp; Sneeuw, N. (2021).        Downscaling GRACE total water storage change using        partial least squares regression. Scientific data, 8(1), 95.       https://doi.org/10.1038/s41597-021-00862-6</p> </li> </ol>"},{"location":"auxillary_codes/","title":"Auxillary Codes","text":"<p>The rest of the important functions have been bundled under the <code>auxillary codes</code> module. </p>"},{"location":"auxillary_codes/#computing-legendre-functions","title":"Computing Legendre functions","text":"<p>The</p>"},{"location":"auxillary_codes/#pyshbundle.plm.derivALF","title":"<code>derivALF(inn, miin, plin, m, lmax)</code>","text":"<p>HelpeFunction</p> <p>Parameters:</p> Name Type Description Default <code>inn</code> <code>_type_</code> <p>description</p> required <code>miin</code> <code>_type_</code> <p>description</p> required <code>plin</code> <code>_type_</code> <p>description</p> required <code>m</code> <code>_type_</code> <p>description</p> required <code>lmax</code> <code>_type_</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>pyshbundle/plm.py</code> <pre><code>def derivALF(inn, miin, plin, m, lmax):\n    \"\"\"HelpeFunction\n\n    Args:\n        inn (_type_): _description_\n        miin (_type_): _description_\n        plin (_type_): _description_\n        m (_type_): _description_\n        lmax (_type_): _description_\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    l = np.arange(m,lmax+2,1)\n    #l=l.reshape(l.shape[0],1)\n    if m == 0:\n        inn[:,0] = 0\n        if lmax &gt; m:             \n            inn[:,1:] = plin*(-np.sqrt(    ((l[1:]+1)*l[1:]   /2).real))            # (-ones(n,1)*realsqrt((l(2:end)+1).*l(2:end)./2)).*plin            \n    elif m == 1:\n        inn[:,0] = miin[:,1]\n        if lmax &gt; m: \n            inn[:,1:] =  miin[:,2:]*(np.sqrt((l[1:]+1)*l[1:]/2).real) -0.5*plin*(np.sqrt((l[1:]-1)*(l[1:]+2)).real)\n    elif m == lmax:\n        inn[:,0] = np.sqrt(m/2*miin[:,1:]).real\n    else:\n        inn[:,0] = np.sqrt((m/2)*miin[:,1:]).real\n        if lmax &gt; m: \n            inn[:,1:] = 0.5*miin[:,2:]*np.sqrt((l[:,1:]+m)*(l[:,1:]-m+1)).real - 0.5*plin*(np.sqrt((l[:,1:]-m)*(l[:,1:]+m+1)).real)\n    return inn\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.plm.lrecur","title":"<code>lrecur(inn, x, m, lmax)</code>","text":"<p>[Helper Function]  </p> <p>Parameters:</p> Name Type Description Default <code>inn</code> <code>_type_</code> <p>description</p> required <code>x</code> <code>_type_</code> <p>description</p> required <code>m</code> <code>_type_</code> <p>description</p> required <code>lmax</code> <code>_type_</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>pyshbundle/plm.py</code> <pre><code>def lrecur(inn, x, m, lmax):\n    \"\"\"[Helper Function]  \n\n    Args:\n        inn (_type_): _description_\n        x (_type_): _description_\n        m (_type_): _description_\n        lmax (_type_): _description_\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    for ll in np.arange(int(m)+1,lmax+1,1):\n       col   = ll - m+1\t\t\t                                                # points to the next collumn of ptmp\n       root1 = np.sqrt( (2*ll+1)*(2*ll-1)/((ll-m)*(ll+m)) ).real \n       root2 = np.sqrt( (2*ll+1)*(ll+m-1)*(ll-m-1) / ( (2*ll-3)*(ll-m)*(ll+m) ) ).real\n\n       # % recursion \n       if ll == m+1:\n           inn[:, col-1] = root1 *x*inn[:, col-2]\n       else:\n           inn[:, col-1] = root1 *x*inn[:, col-2] - root2 *inn[:, col-3] \n    return inn\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.plm.plm","title":"<code>plm(l, m, thetaRAD, nargin, nargout)</code>","text":"<p>PLM Fully normalized associated Legendre functions for a selected order M</p> <p>Parameters:</p> Name Type Description Default <code>l</code> <code>array</code> <p>Degree, but not necessarily monotonic.    For l &lt; m a vector of zeros will be returned.</p> required <code>m</code> <code>int</code> <p>order (scalar). If absent, m = 0 is assumed.</p> required <code>thetaRAD</code> <code>array</code> <p>co-latitude [rad] (vector)</p> required <code>nargin</code> <code>int</code> <p>number of input argument</p> required <code>nargout</code> <code>int</code> <p>number of output argument</p> required <p>Returns:     (np.array): PLM fully normalized</p> Source code in <code>pyshbundle/plm.py</code> <pre><code>def plm(l: np.array, m:int, thetaRAD, nargin, nargout): \n    \"\"\"PLM Fully normalized associated Legendre functions for a selected order M\n\n    Args:\n        l (np.array): Degree, but not necessarily monotonic.\n               For l &lt; m a vector of zeros will be returned.\n        m (int): order (scalar). If absent, m = 0 is assumed.\n        thetaRAD (np.array): co-latitude [rad] (vector)\n        nargin (int): number of input argument\n        nargout (int): number of output argument\n    Returns:\n        (np.array): PLM fully normalized\n    \"\"\"\n\n    if  min(l.shape) != 1:\n        print('Degree l must be a vector (or scalar)') \n        sys.exit([])\n    if  np.remainder(l,1).all() != 0:\n        print('Vector l contains non-integers !!') \n        sys.exit([])\n    # if \n    #     print('Order m must be a scalar') \n    #     sys.exit([])\n    if  np.remainder(m,1) != 0:\n        print('Order must be integer')\n        sys.exit([])\n\n# PRELIMINARIES\n    lcol = len(l)\n    trow = len(thetaRAD)\n    lmax = int(max(l[0,:]))\n\n    if lmax &lt; m:\n        p = np.zeros([len(thetaRAD), len(l)], dtype='longdouble')\n        dp = np.zeros([len(thetaRAD), len(l)], dtype='longdouble')\n        ddp = np.zeros([len(thetaRAD), len(l)], dtype='longdouble')\n        sys.exit([])\n\n    n = thetaRAD.size                                                               # number of latitudes\n    t = thetaRAD[:]\n    x = np.cos(t)\n    y = np.sin(t)\n    lvec = np.transpose(l)   \n    lvec = np.intc(lvec)                                                       # l can now be used as running index\n\n    if min(t).all() &lt; 0 and max(t).all() &gt; np.pi:\n        print('Warning: Is co-latitude in radians ?')\n\n    # Recursive computation of the temporary matrix ptmp, containing the Legendre\n    # functions in its columns, with progressing degree l. The last column of\n    # ptmp will contain zeros, which is useful for assignments when l &lt; m.\n    ptmp = np.zeros((n,lmax + 2 - m))\n    if nargout &gt;= 2:                                                                #  first derivative needs also P_{n,m+1} and P_{n,m-1}\n        ptmp_m1 = np.zeros((n,lmax + 3 - m), dtype='longdouble')\n        ptmp_p1 = np.zeros((n,lmax + 1 -m), dtype='longdouble')        \n        dptmp = np.zeros((n,lmax + 2 - m), dtype='longdouble') \n    if nargout == 3:                                                                # second derivative needs also dP_{n,m+1} and dP_{n,m-1}\n        dptmp_m1 = np.zeros((n,lmax + 3 -m), dtype='longdouble')\n        dptmp_p1 = np.zeros((n,lmax + 1 -m), dtype='longdouble')\n        ptmp_m2 = np.zeros((n,lmax + 4 -m), dtype='longdouble')                                         # but these first derivative need dP_{n,m+2} and dP_{n,m-2}\n        ptmp_p2 = np.zeros((n,lmax - m), dtype='longdouble')\n        ddptmp = np.zeros((n,lmax + 2 -m), dtype='longdouble')\n\n    # sectorial recursion: PM (non-recursive, though)\n    ptmp[:,0] = secrecur(m,y)\n    if nargout &gt;= 2:                                                                # frist derivative needs preceding and subsequent element\n        if m &gt; 0:    \n            ptmp_m1[:,0] = secrecur(m-1,y)                                          # preceding elements\n        if m &lt; lmax: \n            ptmp_p1[:,0] = secrecur(m+1,y)                                          # subsequent elemtens\n    if nargout == 3:                                                                # second derivative needs P_{n,m+2} and P_{n,m-2} as well\n        if m &gt; 1:           \n            ptmp_m2[:,0] = secrecur(m-2,y)                                          # preceding elements\n        if m &lt; lmax-1: \n            ptmp_p2[:,0] = secrecur(m+2,y)                                          # subsequent elemtens\n\n    # l-recursion: P\n    ptmp = lrecur(ptmp,x,m,lmax);\n    if nargout &gt;= 2:                                                                # frist derivative needs preceding and subsequent element\n        if m &gt; 0:\n            ptmp_m1 = lrecur(ptmp_m1,x,m-1,lmax)                                    # preceding elements\n        if m &lt; lmax:\n            ptmp_p1 = lrecur(ptmp_p1,x,m+1,lmax)                                    # subsequent elemtens\n\n    if nargout == 3:                                                                # second derivative needs P_{n,m+2} and P_{n,m-2} as well\n        if m &gt; 1:\n            ptmp_m2 = lrecur(ptmp_m2,x,m-2,lmax)                                    # preceding elements\n        if m &lt; lmax-1:\n            ptmp_p2 = lrecur(ptmp_p2,x,m+2,lmax)                                    # subsequent elemtens\n\n    # now compute the derivatives \n    if nargout &gt;= 2:                                                                # first derivative\n        dptmp = derivALF(dptmp,ptmp_m1,ptmp_p1,m,lmax)\n    if nargout == 3:                                                                # second derivative\n        if m &gt; 0:    \n            dptmp_m1 = derivALF(dptmp_m1,ptmp,ptmp_m2,m-1,lmax)\n        if m &lt; lmax:\n            dptmp_p1 = derivALF(dptmp_p1,ptmp,ptmp_p2,m+1,lmax)\n        ddptmp = derivALF(ddptmp,dptmp_m1,dptmp_p1,m,lmax)\n\n\n    # %--------------------------------------------------------------------\n    # % The Legendre functions have been computed. What remains to be done, is to\n    # % extract the proper columns from ptmp, corresponding to the vector lvec. \n    # % If l or thetaRAD is scalar the output matrix p reduces to a vector. It should\n    # % have the shape of respectively thetaRAD or l in that case.\n    # %--------------------------------------------------------------------\n    lind       = (lvec &lt; m)   \t # index into l &lt; m\n    pcol       = lvec - m + 0\t\t\t                                            # index into columns of ptmp\n    pcol[lind] = np.ndarray((lmax-m+2-6)*np.ones((sum(sum(lind)),1)))\t            # Now l &lt; m points to last col.\n    p      = ptmp[:,pcol]\t\t\t                                                # proper column extraction \n    if nargout &gt;= 2:\n        dp =  dptmp[:,pcol]                                                         # proper column extraction \n    if nargout == 3: \n        ddp = ddptmp[:,pcol]                                                        # proper column extraction  \n    if max(lvec.shape)==1  and min(thetaRAD.shape)==1 and (trow == 1):\n        p = p.T\n        if nargout &gt;= 2:\n            dp  = np.transpose(dp)\n        if nargout == 3:\n            ddp = np.transpose(ddp)\n    if max(thetaRAD.shape)==1 and min(lvec.shape)==1  and (lcol == 1):\n        p = p.T\n        if nargout &gt;= 2:\n            dp  = dp.T  \n        if nargout == 3:\n            ddp = ddp.T\n\n    if nargout == 1: \n        return p\n    if nargout == 2: \n        return p,dp\n    if nargout == 3: \n        return p, dp, ddp\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.plm.secrecur","title":"<code>secrecur(m, y)</code>","text":"<p>Helper Function: </p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>_type_</code> <p>description</p> required <code>y</code> <code>_type_</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>pyshbundle/plm.py</code> <pre><code>def secrecur(m, y):\n    \"\"\"Helper Function: \n\n    Args:\n        m (_type_): _description_\n        y (_type_): _description_\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    if m == 0:\n       fac = 1\n    else:\n       mm  = np.array([2*x for x in range(1, m+1)])\n       fac = np.sqrt(2*np.prod((mm+1)/mm))\n    out = fac*np.power(y,m)                                                         # The 1st column of ptmp\n    return out\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.iplm.iplm","title":"<code>iplm(l, m, theRAD, dt=-9999)</code>","text":"<p>IPLM Integrals of the fully normalized associated Legendre functions     over blocks for a selected order M. </p> <p>Parameters:</p> Name Type Description Default <code>l</code> <code>_type_</code> <p>degree (vector). Integer, but not necessarily monotonic.     For l &lt; m a vector of zeros will be returned.</p> required <code>m</code> <code>int</code> <p>order (scalar)</p> required <code>theRAD</code> <code>array</code> <p>co-latitude [rad] (vector)</p> required <code>dt</code> <code>int</code> <p>integration block-size [rad] (scalar). Defaults to -9999.</p> <code>-9999</code> <p>Returns:</p> Type Description <p>np.ndarray: Matrix with integrated Legendre functions.     Functions are integrated from theRAD(i)-dt/2 till theRAD(i)+dt/2.     The matrix has length(TH) rows and length(L) columns, unless L      or TH is scalar. Then the output vector follows the shape of      respectively L or TH.</p> Notes <p>The blocks at the pole might become too large under circumstances. This is not treated separately, i.e. unwanted output may appear. In case TH is scalar, dt will be 1 (arbitrarily).</p> TO DO <p>Instead of using sys.exit() we could raise exceptions - that would be a better way of error handling</p> Uses <p><code>plm</code></p> Source code in <code>pyshbundle/iplm.py</code> <pre><code>def iplm(l, m:int, theRAD, dt=-9999):\n    \"\"\"IPLM Integrals of the fully normalized associated Legendre functions\n        over blocks for a selected order M. \n\n    Args:\n        l (_type_): degree (vector). Integer, but not necessarily monotonic.\n                For l &lt; m a vector of zeros will be returned.\n        m (int): order (scalar)\n        theRAD (np.array): co-latitude [rad] (vector)\n        dt (int, optional): integration block-size [rad] (scalar). Defaults to -9999.\n\n    Returns:\n        np.ndarray: Matrix with integrated Legendre functions.\n                Functions are integrated from theRAD(i)-dt/2 till theRAD(i)+dt/2.\n                The matrix has length(TH) rows and length(L) columns, unless L \n                or TH is scalar. Then the output vector follows the shape of \n                respectively L or TH.\n\n    Notes:\n        The blocks at the pole might become too large under circumstances.\n        This is not treated separately, i.e. unwanted output may appear.\n        In case TH is scalar, dt will be 1 (arbitrarily).\n\n    TO DO:\n        Instead of using sys.exit() we could raise exceptions - that would be a better way of error handling\n\n    Uses:\n        `plm`\n    \"\"\"\n    if dt == -9999:\n        if len(theRAD) == 1:\n            dt = np.pi/180\n        else:\n            dt = theRAD[1] - theRAD[0]\n    if  min(l.shape) != 1:\n        print('Degree l must be a vector (or scalar)') \n        sys.exit([])\n    if  np.remainder(l,1).all() != 0:\n        print('Vector l contains non-integers !!') \n        sys.exit([])\n    # if \n    #     print('Order m must be a scalar') \n    #     sys.exit([])\n    if  np.remainder(m,1) != 0:\n        print('Order must be integer')\n        sys.exit([])\n    # if min(dt.shape) !=1:\n    #     print('Block size DT must be scalar.') \n        sys.exit([])\n    if dt == 0: \n        print('DT cannot be zero') \n        sys.exit([])\n\n    # init\n    lcol = len(l)\n    trow = len(theRAD)\n    n = len(theRAD)\n    theRAD.T\n    if min(theRAD) &lt; 0 or max(theRAD) &gt; np.pi:\n        print('Is the co-latitude ''theta'' given in radian?')\n        sys.exit([])\n    lmax = max(l[0])\n    mfix = m\n    lvec = np.transpose(l) \n    l = np.arange(mfix,lmax+1,1)\n\n    # Initialization of cosine, sine and Plm functions\n    stplus  = np.sin(theRAD+dt/2)\n    stmin   = np.sin(theRAD-dt/2)\n    ctplus  = np.cos(theRAD+dt/2)\n    ctmin   = np.cos(theRAD-dt/2)\n    plmplus = np.ones([n,lmax+1])\n    plmmin = np.ones([n,lmax + 1])\n    plmplus[:,l] = plm.plm(np.array([l]),mfix,(theRAD + dt/2),3,1)[:,:,0]                  # Tesserals\n    plmmin[:,l] = plm.plm(np.array([l]),mfix,(theRAD - dt/2),3,1)[:,:,0] \n    if mfix &gt; 0:\n        m = np.arange(1,mfix + 1,1)\n        mm = 2*m\n        fac = np.sqrt(2*np.cumprod((mm+1)/mm))\n        mgr, stp = np.meshgrid(m, stplus)\n        fgr, stm = np.meshgrid(fac, stmin)\n        plmplus[:, m] = fgr * np.power(stp, mgr)\n        plmmin[:, m] = fgr * np.power(stm, mgr)\n    ptmp = np.zeros([n, lmax +2 ])\n    ptmp00 = np.cos(theRAD - dt/2) - ctplus\n    ptmp11 = np.sqrt(3)/2 * (dt - ctplus* stplus + ctmin* stmin)\n    ptmp10 = np.sqrt(3)/2 * (np.power(stplus,2) - np.power(stmin,2))\n    ptmp[:,0] = ptmp00\n\n    # Compute first the integrals of order m == 0\n    if mfix == 0:\n        ptmp[:,1] = ptmp10\n        for l in range(2,lmax+1,1):              #loop over the degree l \n            rootnm = np.sqrt( (2*l+1)*(2*l-1)/np.power(l,2))\n            root1nm = np.sqrt( (2*l-1)*(2*l-3)/np.power(l-1,2))\n            ptmp[:,l] = rootnm/(l+1)*(((l-2)*ptmp[:,l-2]/root1nm).T + np.power(stplus,2)*plmplus[:,l-1].T - np.power(stmin,2)*plmmin[:,l-1].T )\n    else:\n        # Compute the integrals of order m &gt; 0\n\n        # First we compute the diagonal element IPmm (lmax == mfix)\n\n        ptmp[:,1] = ptmp11\n        for l in range(2,mfix+1,1):\n            # print(l)\n            rootmm = np.sqrt( (2*l+1)/(2*l) )\n            root1mm = np.sqrt( (2*l-1)/(2*l-2))\n            if l == 2:\n                root1mm = np.sqrt(3)\n\n            ptmp[:,l] = rootmm/(l+1)*( l*root1mm*ptmp[:,l-2].T - (ctplus*plmplus[:,l].T -ctmin*plmmin[:,l].T)/rootmm )\n    #the arbitrary element IPlm ( computed only when lmax &gt; mfix)        \n        if lmax &gt; mfix:\n            l = mfix + 1\n        #first we do the element IPlm, for which l - m = 1    \n            rootnm = np.sqrt( (2*l+1)*(2*l-1)/(l+mfix)/(l-mfix))\n            ptmp[:,l] = rootnm/(l+1)*(np.power(stplus,2)*plmplus[:,l-1].T - np.power(stmin,2)*plmmin[:,l-1].T)\n        #now we do the rest\n            for l in range(mfix+2,lmax+1,1):              #loop over the degree l\n                rootnm = np.sqrt( (2*l+1) * (2*l-1) / (l+mfix) / (l-mfix) )\n                root1nm = np.sqrt( (2*l-1) * (2*l-3) / (l-1+mfix) / (l-1-mfix) )\n                ptmp[:,l] = rootnm/(l+1)*( (l-2)*ptmp[:,l-2].T/root1nm + np.power(stplus,2)*plmplus[:,l-1].T -np.power(stmin,2)*plmmin[:,l-1].T)\n\n\n# The integrated functions have been computed. What remains to be done, is to\n# extract the proper columns from ptmp, corresponding to the vector lvec. \n# If l or theta is scalar the output matrix p reduces to a vector. It should\n# have the shape of respectively theta or l in that case.\n\n# p     = zeros(n, length(lvec))\n    lind = np.argwhere(lvec&lt;mfix)[:,0]      #index into l &lt; m\n    pcol = lvec + 1                         #index into columns of ptmp\n    pcol[lind] = (lmax + 2)*np.ones([len(lind),1])   #Now l &lt; m points to last col\n    p = ptmp[:,pcol[:,0]-1]                 #proper column extraction \n\n    if max(lvec.shape) == 1 and min(np.array([theRAD]).shape) == 1 and trow == 1:\n        p = p.T\n    if max(np.array([theRAD]).shape) == 1 and min(lvec.shape) == 1 and lcol == 1:\n        p = p.T\n    return p\n</code></pre>"},{"location":"auxillary_codes/#grace-data-pre-processing","title":"GRACE Data Pre-Processing","text":""},{"location":"auxillary_codes/#pyshbundle.GRACEpy.lovenr","title":"<code>lovenr(lmax)</code>","text":"<p>Created on Mon May 11 11:09:28 2022</p> Todo <ul> <li>Add type and input checking functionality</li> </ul> <p>author: Dr. Bramha Dutt Vishwakarma, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)</p> Source code in <code>pyshbundle/GRACEpy.py</code> <pre><code>def lovenr(lmax: int):\n    \"\"\"\n    Created on Mon May 11 11:09:28 2022\n\n    Todo:\n        + Add type and input checking functionality\n\n    _author_: Dr. Bramha Dutt Vishwakarma, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n    \"\"\"\n    l  = [0,  1,    2,    3,    4,    5,   6,   7,   8,   9,  10,  12,  15,  20,  30,  40,  50,  70, 100, 150, 200]\n    kl = numpy.divide([0,270,-3030,-1940,-1320,-1040,-890,-810,-760,-720,-690,-640,-580,-510,-400,-330,-270,-200,-140,-100, -700],1e4)\n    n = range(0, lmax+1, 1)\n    kn = numpy.interp(n,l,kl)\n    return(kn)\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.GRACEpy.lovenrPREM","title":"<code>lovenrPREM(lmax, frame)</code>","text":"<p>Created on Mon May 11 11:51:29 2022</p> <p>@author:  Dr. Bramha Dutt Vishwakarma, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)</p> Source code in <code>pyshbundle/GRACEpy.py</code> <pre><code>def lovenrPREM(lmax:int, frame):\n    \"\"\"\n    Created on Mon May 11 11:51:29 2022\n\n    @author:  Dr. Bramha Dutt Vishwakarma, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n    \"\"\"\n\n    data = numpy.array([[ 1,  -0.28476,   0.00000,   0.10462],\n    [2,  -0.99297,  -0.61274,   0.04661] ,\n    [3,  -1.05142,  -0.58897 ,  0.21048] ,\n    [4,  -1.05378,  -0.53513 ,  0.23564] ,\n    [5,  -1.08658,  -0.52382 ,  0.23186] ,\n    [6,  -1.14404,  -0.54222 ,  0.23263] ,\n    [7,  -1.21254,  -0.57464 ,  0.24058] ,\n    [8,  -1.28403,  -0.61256 ,  0.25308] ,\n    [9,  -1.35479,  -0.65203 ,  0.26799] ,\n    [10,  -1.42330,  -0.69140,   0.28419] ,\n    [11,  -1.48909,  -0.72998,   0.30121] ,\n    [12,  -1.55204,  -0.76749,   0.31880] ,\n    [13,  -1.61221,  -0.80381,   0.33684] ,\n    [14,  -1.66968,  -0.83886,   0.35522] ,\n    [15,  -1.72454,  -0.87260,   0.37382] ,\n    [16,  -1.77684,  -0.90499,   0.39251] ,\n    [17,  -1.82668,  -0.93599,   0.41119] ,\n    [18,  -1.87414,  -0.96560,   0.42973] ,    \n    [19,  -1.91928,  -0.99382,   0.44804] ,\n    [20,  -1.96220,  -1.02066,   0.46603] ,\n    [21,  -2.00297,  -1.04614,   0.48363] ,\n    [22,  -2.04169,  -1.07029,   0.50078] ,\n    [23,  -2.07844,  -1.09313,   0.51742] ,\n    [24,  -2.11332,  -1.11472,   0.53355] ,\n    [25,  -2.14642,  -1.13511,   0.54912] ,\n    [30,  -2.28839,  -1.22067,   0.61848] ,\n    [40,  -2.48641,  -1.33024,   0.71925] ,\n    [50,  -2.61710,  -1.39016,   0.78410] ,\n    [60,  -2.71254,  -1.42377,   0.82683] ,\n    [70,  -2.78865,  -1.44313,   0.85550] ,\n    [80,  -2.85368,  -1.45474,   0.87479] ,\n    [90,  -2.91216,  -1.46226,   0.88764] ,\n    [100,  -2.96672,  -1.46787,   0.89598] ,\n    [120,  -3.06983,  -1.47811,   0.90421] ,\n    [140,  -3.16950,  -1.49082,   0.90634] ,\n    [160,  -3.26809,  -1.50771,   0.90603] ,\n    [180,  -3.36633,  -1.52909,   0.90532] ,\n    [200,  -3.48436,  -1.55473,   0.90547] ,\n    [250,  -3.70773,  -1.63448,   0.91388] ,\n    [300,  -3.94607,  -1.73053,   0.93714] ,\n    [350,  -4.17591,  -1.83593,   0.97495] ,\n    [400,  -4.39433,  -1.94515,   1.02467] ,\n    [500,  -4.78872,  -2.15940,   1.14615] ,\n    [600,  -5.12008,  -2.35243,   1.27714] ,\n    [800,  -5.59959,  -2.64798,   1.50995] ,\n    [1000,  -5.88447,  -2.83157,  1.67325] ,\n    [1500,  -6.15106,  -3.00957,   1.84797] ,\n    [2000,  -6.20058,  -3.04408,   1.88423] ,\n    [3000,  -6.21044,  -3.05176,   1.89114] ,\n    [5000,  -6.21155,  -3.05324,   1.89118] ,\n    [10000,  -6.21226,  -3.05427,   1.89110]])\n\n    l  =  data[:,0]\n    hl =  data[:,1]\n    kl =  numpy.divide(data[:,2], l)\n    ll =  numpy.divide(data[:,3], l)\n\n    if frame == 'CM':\n        hl[0] = hl[0] - 1\n        ll[0] = ll[0] - 1\n        kl[0] = kl[0] - 1\n        print('Love numbers are in center of mass frame')\n    elif frame == 'CF':\n        hlo = hl[0]\n        llo = ll[0]\n        hl[0] = (hlo - llo) * 2/3\n        ll[0] = (hlo - llo) * (-1/3)\n        kl[0] = ((-2/3)*llo) - ((-1/3)*hlo)\n        print('Love numbers are in center of figure frame')\n    elif frame == 'CE':\n        print('Love numbers are in center of solid Earth frame')\n    else:\n        lovenrPREM.exit('Please choose a compatible frame of reference: one of CM, CF, or CE')\n\n\n    n = range(0, lmax+1, 1)\n    kn = numpy.interp(n,l,kl)\n    hn = numpy.interp(n,l,hl)\n    ln = numpy.interp(n,l,ll)\n    kn[0] = 0 \n    hn[0] = 0\n    ln[0] = 0\n    return(kn,hn,ln)\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.GRACEpy.upwcon","title":"<code>upwcon(degree, height)</code>","text":"<p>Returns the upward continuation \\((R/r)^l\\)</p> <p>Parameters:</p> Name Type Description Default <code>degree</code> <code>int</code> <p>Spherical harmonic degree</p> required <code>height</code> <code>int</code> <p>Height above mean Earth radius [m] [scalar/vector]</p> required <p>Returns:</p> Name Type Description <code>uc</code> <code>_type_</code> <p>Upward continuation terms</p> Uses <p><code>GRACEconstants.GC</code></p> Todo <ul> <li>Add input checking functionality and raise exceptions</li> <li>Add reference to formula</li> </ul> Source code in <code>pyshbundle/GRACEpy.py</code> <pre><code>def upwcon(degree: int, height):\n    \"\"\"Returns the upward continuation $(R/r)^l$\n\n    Args:\n        degree (int): Spherical harmonic degree\n        height (int): Height above mean Earth radius [m] [scalar/vector]\n\n    Returns:\n        uc (_type_): Upward continuation terms\n\n    Uses:\n        `GRACEconstants.GC`\n\n    Todo:\n        + Add input checking functionality and raise exceptions\n        + Add reference to formula\n    \"\"\"\n    # Created on Sat May  9 18:49:45 2022\n    rr = numpy.divide(GC.ae, numpy.add(GC.ae,height))\n    uc = numpy.power(rr, degree)\n\n    return(uc)    \n</code></pre>"},{"location":"auxillary_codes/#filtering-the-grace-data","title":"Filtering the GRACE Data","text":""},{"location":"auxillary_codes/#pyshbundle.gaussian.gaussian","title":"<code>gaussian(L, cap)</code>","text":"<p>The program delivers the spherical harmonic coefficients of a gaussian smoothing filter. The coefficients are calculated according to Wahr et. al.(1998) equation (34) and Swenson and Wahr equation (34)</p> <p>Parameters:</p> Name Type Description Default <code>L</code> <code>int</code> <p>maximum degree</p> required <code>cap</code> <code>int</code> <p>half width of Gaussian smoothing function [km]</p> required <p>Returns:</p> Type Description <p>np.ndarray: smoothing coefficients</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>Degree must be integer</p> <code>ValueError</code> <p>Maximum degree must be higher than 2</p> <code>TypeError</code> <p>Cap size must be an integer</p> References <p>Wahr et.al. (1998) equation (34) and Swenson and Wahr equation (34)</p> Source code in <code>pyshbundle/gaussian.py</code> <pre><code>def gaussian(L: int, cap: int):\n    \"\"\"The program delivers the spherical harmonic coefficients of a gaussian\n    smoothing filter. The coefficients are calculated according to Wahr et. al.(1998)\n    equation (34) and Swenson and Wahr equation (34)\n\n\n    Args:\n        L (int): maximum degree\n        cap (int): half width of Gaussian smoothing function [km]\n\n    Returns:\n        np.ndarray: smoothing coefficients\n\n    Raises:\n        TypeError: Degree must be integer\n        ValueError: Maximum degree must be higher than 2\n        TypeError: Cap size must be an integer\n\n    References:\n        Wahr et.al. (1998) equation (34) and Swenson and Wahr equation (34)\n\n    \"\"\"\n\n    #Check input\n    if type(L) != int:\n        raise TypeError('Degree must be integer')\n\n    if L&lt;2:\n        raise ValueError('Maximum degree must be higher than 2')\n\n    if type(cap) != int:\n        raise TypeError('Cap size must be an integer')\n\n    #Calculations\n    W = np.zeros([L+1, 1])\n    b = np.log(2)/(1 - np.cos(cap/6371))\n\n    #Recursive calculation of the weighting coefficients\n    W[0,0] = 1\n    W[1,0] = np.power(10, np.log10( (1 + np.exp(-2*b))/(1-np.exp(-2*b)) - (1/b)))\n\n    i = 1\n    while i &lt; L:        \n        j = i + 1\n        W[i+1][0] = W[i-1][0] - (2*(j-1) + 1)/b * W[i][0]\n        if W[i+1, 0] &gt; W[i] or W[i+1] &lt; 0:\n            W[i+1] = 0\n        i = i + 1\n\n    return W\n</code></pre>"},{"location":"auxillary_codes/#numerical-integration","title":"Numerical Integration","text":""},{"location":"auxillary_codes/#pyshbundle.grule.grule","title":"<code>grule(n)</code>","text":"<p>This function computes Gauss base points and weight factors using the algorithm-see Reference</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>number of base points required</p> required <p>Returns:</p> Type Description <p>np.array: cosine of the base points</p> <p>np.array: weight factors for computing integrals and such</p> References <ol> <li>'Methods of Numerical Integration' by Davis and Rabinowitz, page 365, Academic Press, 1975.</li> </ol> Source code in <code>pyshbundle/grule.py</code> <pre><code>def grule(n: int):\n    \"\"\"This function computes Gauss base points and weight factors\n    using the algorithm-see Reference\n\n    Args:\n        n (int): number of base points required\n\n    Returns:\n        np.array: cosine of the base points\n        np.array: weight factors for computing integrals and such\n\n    References:\n        1. 'Methods of Numerical Integration' by Davis and Rabinowitz, page 365, Academic Press, 1975.\n\n    \"\"\"\n    bp = np.zeros((n,1))\n    wf = bp\n    iter = 2\n    m = np.floor((n+1)/2)\n    e1 = n * (n+1)\n\n\n    mm = 4*m - 1\n    t = (np.pi / (4*n + 2)) * np.arange(3,mm+4,4)\n    nn = (1 - (1 - 1/n)/(8*n*n))\n    x0 = nn * np.cos(t)\n\n\n    for i in range(iter):\n        pkm1 = 1\n        pk = x0\n\n        for kk in range(n-1):\n            k = kk + 2\n            t1 = x0 * pk\n            pkp1 = t1 - pkm1 - (t1-pkm1)/k  + t1\n            pkm1=pk\n            pk=pkp1\n\n        den = 1 - x0*x0\n        d1 = n * (pkm1 - x0*pk)\n        dpn = d1/den\n\n\n        d2pn = (2*x0*dpn - e1*pk) / den\n        d3pn = (4*x0*d2pn + (2-e1)*dpn)/den\n        d4pn = (6*x0*d3pn + (6-e1)*d2pn)/den\n        u = pk/dpn\n        v = d2pn/dpn\n        h = -u * (1+(.5*u)*(v+u*(v*v - u*d3pn/(3*dpn))))\n        p = pk + h*(dpn+(0.5*h)*(d2pn+(h/3)*(d3pn + 0.25*h*d4pn)))\n        dp = dpn + h*(d2pn+(0.5*h)*(d3pn+h*d4pn/3))\n        h = h-p/dp\n        x0 = x0+h\n\n    bp = -x0-h\n    fx = d1 - h*e1*(pk+(h/2)*(dpn+(h/3)*(d2pn+(h/4)*(d3pn+(0.2*h)*d4pn))))\n    wf = [2 * (1 - np.power(bp,2))]/(fx*fx)\n\n\n    for i in range(len(bp),n):\n        bp = np.append(bp,[0])\n        wf = np.append(wf,[0])\n\n    if ((m)+(m)) != (n):\n        m = m-1\n\n    for i in range(1,int(m+1)):\n        bp[-i] = -bp[i-1]\n        wf[-i] = wf[i-1] \n    return bp, wf\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.naninterp.naninterp","title":"<code>naninterp(X)</code>","text":"<p>This function uses cubic interpolation to replace NaNs</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>_type_</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>pyshbundle/naninterp.py</code> <pre><code>def naninterp(X):\n    \"\"\"This function uses cubic interpolation to replace NaNs\n\n    Args:\n        X (_type_): _description_\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n\n    nan = np.nan\n\n    ok = ~np.isnan(X)\n    xp = ok.ravel().nonzero()[0] #Indices of xs with values\n    fp = X[~np.isnan(X)]\n\n    x  = np.isnan(X).ravel().nonzero()[0] #Indices of xs without values\n\n    pchip = PchipInterpolator(xp,fp) #Initialize scipy PHCIP cubic interpolation\n    X[np.isnan(X)] = pchip(x) #Interpolate Nan values in X\n\n    return X\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.neumann.neumann","title":"<code>neumann(inn)</code>","text":"<p>Returns the weights and nodes for Neumann's numerical integration</p> <p>Parameters:</p> Name Type Description Default <code>inn</code> <code>(int, array)</code> <p>base points (nodes) in the interval [-1;1]</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>Integer input argument required</p> <code>ValueError</code> <p>Error in input dimensions</p> <p>Returns:</p> Name Type Description <code>_type_</code> <p>quadrature weights</p> <code>_type_</code> <p>base points (nodes) in the interval [-1;1]</p> Remarks <ul> <li>1st N.-method: see Sneeuw (1994) GJI 118, pp 707-716, eq. 19.5</li> <li>2nd N.-method: see uberall/GRULE</li> </ul> Todo <ul> <li>TypeError is more relavant and shape error from numpy</li> </ul> Uses <p><code>grule</code>, <code>plm</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; TO DO: write example how to use the function\n</code></pre> Source code in <code>pyshbundle/neumann.py</code> <pre><code>def neumann(inn):\n    \"\"\"Returns the weights and nodes for Neumann's numerical integration\n\n    Args:\n        inn (int, np.array): base points (nodes) in the interval [-1;1]\n\n    Raises:\n        TypeError: Integer input argument required\n        ValueError: Error in input dimensions\n\n    Returns:\n        _type_: quadrature weights\n        _type_: base points (nodes) in the interval [-1;1]\n\n    Remarks:\n        * 1st N.-method: see Sneeuw (1994) GJI 118, pp 707-716, eq. 19.5\n        * 2nd N.-method: see uberall/GRULE\n\n    Todo: \n        + TypeError is more relavant and shape error from numpy\n\n    Uses:\n        `grule`, `plm`\n\n    Examples:\n        &gt;&gt;&gt; TO DO: write example how to use the function\n    \"\"\"\n\n    try: #if input is an integer\n        x, w = grule.grule(inn)\n    except: #if input is an array\n        if(len(inn)==1): #2nd Neumann method\n            x, w = grule.grule(inn)\n            if(np.not_equal(np.mod(x, 1), 0)): #Not integer\n                raise TypeError(\"Integer input argument required\")\n\n\n\n        elif min(inn.shape) == 1: #1st Neumann method #Size gives 2 outputs for 2d array in matlab; for row and column\n            x = inn\n            theRAD = np.arccos(x) #x in radian\n            l = np.array(list(range(len(x))))\n            pp = plm.plm(l, theRAD)\n\n            rr = list([2])\n            for i in len(x-1):\n                rr.append(0)\n            r = np.asarray(rr)\n\n            w,resid,rank,s = np.linalg.lstsq(pp,r) #Solve system of equations; Double check this operation\n            if(x.shape != w.shape):\n                w = w.T\n\n        else:\n            raise ValueError(\"Error in input dimensions\")\n            # TO DO: Write more descriptive exception messages\n\n    return w, x\n</code></pre>"},{"location":"auxillary_codes/#important-for-spherical-harmonic-synthesis","title":"Important for Spherical Harmonic Synthesis","text":""},{"location":"auxillary_codes/#pyshbundle.ispec.ispec","title":"<code>ispec(a, b=-9999)</code>","text":"<p>Returns the function F from the spectra A and B</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>_type_</code> <p>cosine coefficients</p> required <code>b</code> <code>int</code> <p>sine coefficients. Defaults to -9999.</p> <code>-9999</code> <p>Returns:</p> Name Type Description <code>f</code> <code>_type_</code> <p>description</p> See Also <p><code>spec</code></p> Source code in <code>pyshbundle/ispec.py</code> <pre><code>def ispec(a,b = -9999):\n    \"\"\"Returns the function F from the spectra A and B\n\n    Args:\n        a (_type_): cosine coefficients\n        b (int, optional): sine coefficients. Defaults to -9999.\n\n    Returns:\n        f (_type_): _description_\n\n    See Also:\n        `spec`\n    \"\"\"\n\n    n2 = a.shape[0]\n    a[0,:] = a[0, :]*2\n\n\n    if (np.absolute(b[n2-1,:]) &lt; 1e-10).all():\n        n = 2 * n2 - 2     \n        a[n2-1,:] = a[n2-1,:] * 2            \n        fs = (a - 1j * b)/2\n        fs  = (np.concatenate((fs,np.conj(fs[np.arange(n2-2,0,-1),:])), axis = 0))*max(n,1)\n\n    else:\n        n = 2 * n2 - 1                        \n        fs = (a - 1j * b)/2\n        fs = (np.concatenate((fs,np.conj(fs[np.arange(n2-1,0,-1),:])), axis = 0))*n\n\n    f = np.real(scipy.fft.ifft(fs.T).T)\n    return f\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.normalklm.normalklm","title":"<code>normalklm(lmax, typ='wgs84')</code>","text":"<p>NORMALKLM returns an ellipsoidal normal field consisting of normalized -Jn, n=0,2,4,6,8</p> <p>Parameters:</p> Name Type Description Default <code>lmax</code> <code>int</code> <p>maximum degree</p> required <code>typ</code> <code>str</code> <p>Ellipsoids can be either          'wgs84' - World Geodetic System 84,          'grs80' - ,          'he' - hydrostatic equilibrium ellipsoid</p> <code>'wgs84'</code> <p>Returns:</p> Name Type Description <code>nklm</code> <code>array</code> <p>normal field in CS-format (sparse array - [1, -J2, -J4, -J6, -J8])</p> TODO <p>Find type of nklm; I think raising TypeError, VlueError or NameError instad of general Exception</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>lmax should be an integer</p> <code>ValueError</code> <p>lmax should be positive</p> <code>ValueError</code> <p>Unknown type of ellipsoid, supports 'wgs84', <code>GRS80</code> and 'he'</p> References <ol> <li>J2,J4 values for hydrostatic equilibrium ellipsoid from Lambeck (1988) \"Geophysical Geodesy\", p.18</li> </ol> Source code in <code>pyshbundle/normalklm.py</code> <pre><code>def normalklm(lmax: int, typ: str = 'wgs84'):\n    \"\"\" NORMALKLM returns an ellipsoidal normal field\n    consisting of normalized -Jn, n=0,2,4,6,8\n\n    Args:\n        lmax (int): maximum degree\n        typ (str): Ellipsoids can be either \n                    'wgs84' - World Geodetic System 84, \n                    'grs80' - , \n                    'he' - hydrostatic equilibrium ellipsoid\n\n    Returns:\n        nklm (np.array): normal field in CS-format (sparse array - [1, -J2, -J4, -J6, -J8])\n\n    TODO: \n        Find type of nklm; I think raising TypeError, VlueError or NameError instad of general Exception\n\n    Raises:\n        TypeError: lmax should be an integer\n        ValueError: lmax should be positive\n        ValueError: Unknown type of ellipsoid, supports 'wgs84', `GRS80` and 'he'\n\n    References:\n        1. J2,J4 values for hydrostatic equilibrium ellipsoid from Lambeck (1988)\n        \"Geophysical Geodesy\", p.18    \n    \"\"\"\n\n    if type(lmax) != int:\n        raise TypeError(\"lmax should be integer\")\n\n    if lmax &lt; 0:\n        raise ValueError(\"lmax should be positive\")\n\n\n    typ_ = typ.lower()\n    if (typ_ == 'wgs84'):\n        J2     =  1.08262982131e-3     #% earth's dyn. form factor (= -C20 unnormalized)\n        J4     = -2.37091120053e-6    #% -C40 unnormalized\n        J6     =  6.08346498882e-9     #% -C60 unnormalized\n        J8     = -1.42681087920e-11    #% -C80 unnormalized\n        jcoefs = np.array([1, -J2, -J4, -J6, -J8]).T.reshape(5,1)\n        # as lmax + 2 is requires \n        l      = np.arange(0,min(lmax + 2,8 + 2), 2).T\n        l.reshape(l.shape[0],1)\n\n    elif (typ_ == 'grs80'):\n        J2     =  1.08263e-3         # % earth's dyn. form factor (= -C20 unnormalized)\n        J4     = -2.37091222e-6     #% -C40 unnormalized\n        J6     =  6.08347e-9        #% -C60 unnormalized\n        J8     = -1.427e-11         #% -C80 unnormalized\n        jcoefs = np.array([1, -J2, -J4, -J6, -J8]).reshape(5,1)\n        l      = np.arange(0,min(lmax + 2,8 + 2), 2).T\n        l.reshape(l.shape[0],1)\n\n    elif ((typ_ == 'he') or (typ_ == 'hydro')):\n        J2     = 1.072618e-3\t\t#% earth's dyn. form factor (= -C20 unnormalized)\n        J4     = 0.2992e-5     \t#% -C40 unnormalized\n        jcoefs = np.array([1, -J2, -J4]).T.reshape(5,1)\n        # adding (2) beacuse of arange function is only uptp last integer and not including last\n        l      = np.arange(0,min(lmax + 2,4 + 2), 2).T\n        l.reshape(l.shape[0],1)\n\n    else:\n        raise ValueError(\"Unknown type of ellipsoid:   \", typ)\n\n    coefs = jcoefs[:len(l)].T / np.sqrt(2*l + 1)\n#    coefs.reshape(coefs.shape[0],1)\n\n\n    data = np.array(coefs)[0]\n    row = np.array(l)\n    col = np.zeros(len(l))\n    # lmax = 96 then shape=(97, 97) -&gt; consisitent with everything else\n    nklm = sparse.coo_matrix((data,(row,col)),shape=(lmax+1,lmax+1)).toarray()\n    return nklm\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.eigengrav.eigengrav","title":"<code>eigengrav(lmax, fstr, h)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>lmax</code> <code>int</code> <p>Maximum degree of Spherical Coefficients</p> required <code>fstr</code> <code>str</code> <p>gravity quantity, options: 'None', 'geoid', 'potential', 'gravity', 'tr', 'trr', 'slope'         'water', 'smd', 'height'</p> required <code>h</code> <code>float</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>Enter a valid lmax value</p> TO DO <p>Can we think about the raising a ValueError instead of instantly terminating the function Adding comments as variable names are not much descriptive</p> Source code in <code>pyshbundle/eigengrav.py</code> <pre><code>def eigengrav(lmax: int, fstr: str, h: float):\n    \"\"\"_summary_\n\n    Args:\n        lmax (int): Maximum degree of Spherical Coefficients\n        fstr (str): gravity quantity, options: 'None', 'geoid', 'potential', 'gravity', 'tr', 'trr', 'slope'\n                    'water', 'smd', 'height'\n        h (float): _description_\n\n    Returns:\n        _type_: _description_\n\n    Raises:\n        TypeError: Enter a valid lmax value\n\n    TO DO:\n        Can we think about the raising a ValueError instead of instantly terminating the function\n        Adding comments as variable names are not much descriptive\n    \"\"\"\n\n    if type(lmax) == int:\n        rows = 1\n    else:\n        rows = len(lmax)\n    # rows = len(l)\n\n    if rows &gt; 1 or lmax &lt; 0:\n        raise TypeError(\"Enter a valid lmax value\")\n\n    r = GC.ae + h\n\n    # lmax issue - using lmax as per used in shbundle\n    # no reference for height\n\n    if fstr == 'none':\n        tf = numpy.ones((1, lmax+1))\n    elif fstr == 'geoid':\n        tf = numpy.ones((1, lmax+1)) * r\n    elif fstr == 'potential':\n        tf = numpy.ones((1, lmax+1)) * (GC.GM/r)\n    elif fstr == 'gravity' or fstr == 'dg':\n        tf = numpy.multiply(range(-1, lmax, 1), ((GC.GM/r/r) * 1e5))\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'tr':\n        tf = numpy.multiply(range(-1, -(lmax+2), -1), ((GC.GM/r/r) * 1e5))\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'trr':\n        tf = numpy.multiply(range(1, (lmax+2), 1),\n                            range(2, (lmax + 3), 1))*((GC.GM/r/r) * 1e9)\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'slope':\n        tf = numpy.sqrt(numpy.multiply(\n            range(0, lmax+1, 1), range(1, lmax+2, 1)))\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'water':\n        ln = GB.lovenr(lmax)\n        tf = numpy.divide(numpy.multiply(\n            5.517*r, numpy.add(range(0, 2*lmax + 1, 2), 1)), numpy.multiply(3, (1+ln)))\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'smd':\n        ln = GB.lovenr(lmax)\n        tf = numpy.divide(numpy.multiply(\n            5517*r, numpy.add(range(0, 2*lmax + 1, 2), 1)), numpy.multiply(3, (1+ln)))\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'height':\n        # not sure aobut heights - kept it unchanged ... abhishek\n        kl, hl, ll = GB.lovenrPREM(90, 'CF')\n        tf = numpy.divide(numpy.multiply(hl, (GC.ae*1000)), numpy.add(kl, 1))\n    else:\n        ValueError('Please choose a valid quantity for fstr')\n\n    if h &gt; 0:\n        upConTerm = GB.upwcon(lmax, h)\n        tf = numpy.multiply(tf, upConTerm)\n\n    return(tf)\n</code></pre>"},{"location":"auxillary_codes/#time-series","title":"Time Series","text":""},{"location":"auxillary_codes/#pyshbundle.Phase_calc.Phase_calc","title":"<code>Phase_calc(fts, ffts)</code>","text":"<p>calculates the phase difference between two time series based on the Hilbert transform method explained by Phillip et al.</p> <p>Parameters:</p> Name Type Description Default <code>fts</code> <code>ndarray</code> <p>description</p> required <code>ffts</code> <code>ndarray</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> References <ol> <li>Phillips, T., R. S. Nerem, B. Fox-Kemper, J. S. Famiglietti, and B. Rajagopalan (2012), The influence of ENSO on global terrestrial water storage using GRACE, Geophysical Research Letters, 39 (16), L16,705, doi:10.1029/2012GL052495.</li> </ol> Source code in <code>pyshbundle/Phase_calc.py</code> <pre><code>def Phase_calc(fts, ffts):\n    \"\"\"calculates the phase difference between two time series based on the\n    Hilbert transform method explained by Phillip et al.\n\n    Args:\n        fts (np.ndarray): _description_\n        ffts (np.ndarray): _description_\n\n    Returns:\n        _type_: _description_\n\n    References:\n        1. Phillips, T., R. S. Nerem, B. Fox-Kemper, J. S. Famiglietti, and B. Rajagopalan (2012),\n        The influence of ENSO on global terrestrial water storage using GRACE, Geophysical\n        Research Letters, 39 (16), L16,705, doi:10.1029/2012GL052495.\n    \"\"\"\n    c = fts.shape[1]\n\n    ps = np.zeros((1, c))\n\n    filter_ = ~np.isnan(fts)\n    filter__ = ~np.isnan(ffts)\n\n    fts_ = fts[filter_] #Extract values and leave Nan\n    ffts_ = ffts[filter__] #Extract values and leave Nan\n\n    fts = fts_.reshape(int(fts_.shape[0]/c),c)\n    ffts = ffts_.reshape(int(ffts_.shape[0]/c),c)\n\n    rn = fts.shape[0]\n\n    for i in range(c):\n        # A = np.concatenate(np.ones((rn,1)), np.real(signal.hilbert(ffts[:, i])), np.imag(signal.hilbert(ffts[:, i]))) #design matrix\n\n        A = np.array((np.ones((rn)), np.real(signal.hilbert(ffts[:, i])), np.imag(signal.hilbert(ffts[:, i])))).T\n\n        A = A.astype('double')\n        B = fts[:,i]\n        B = B.astype('double')\n        abc = np.linalg.lstsq(A.T @ A, A.T @ B)[0]\n\n        ps[0,i] = np.arctan2(abc[3-1],abc[2-1])*(180/np.pi) #check indices and degree/radian\n    return ps\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/mn5hk/pyshbundle/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>pyshbundle could always use more documentation, whether as part of the official pyshbundle docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/mn5hk/pyshbundle/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up pyshbundle for local development.</p> <ol> <li> <p>Fork the pyshbundle repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/pyshbundle.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv pyshbundle\n$ cd pyshbundle/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 pyshbundle tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.5, 3.6, 3.7 and 3.8, and     for PyPy. Check https://github.com/mn5hk/pyshbundle/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"convert_data_formats/","title":"Convert Data Formats","text":"<p>Spherical harmonic functions or coefficients, Legendre functions and their derivatives can be arranged in different ways. There are multiple functions in SHBundle for reordering from one format to another. Some of them have been translated to Python in PySHBundle. Couple of new ones have also been added.</p>"},{"location":"convert_data_formats/#spherical-harmonics-data-formats","title":"Spherical Harmonics Data Formats","text":""},{"location":"convert_data_formats/#clm-format","title":"clm-format","text":"<p>This is a standard format to store spherical harmonic coefficients in the indexed column-vector-format (abbreviatedL clm-format)</p> \\[\\begin{equation}   \\left( n, m, \\overline{C}_{n, m}, \\overline{S}_{n, m}, \\left[ \\sigma_{\\overline{C}_{n, m}}, \\sigma_{\\overline{S}_{n, m}} \\right] \\right) \\end{equation}\\] <p>The first column represents the degree \\(n\\), the second column represents the order \\(m\\) (both n,m are integers), followed by the coefficients \\(\\overline{C}_{n, m}, \\overline{S}_{n, m}\\) and the last two columns contain their respective standard deviations \\(\\sigma_{\\overline{C}_{n, m}}, \\sigma_{\\overline{S}_{n, m}}\\)</p>"},{"location":"convert_data_formats/#klm-format","title":"klm-format","text":"<p>This is a variation of the clm-format for compact notation with just 3 or 4 columns. The coefficients are sorted first w.r.t. degree and then the order, particularly the sine-coefficients are arranged starting first with negative orders. The following matrix represents the klm-format:</p> <pre><code>\\begin{bmatrix}\n  0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\\n  0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\\n  0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\\n  0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\\n  0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\\n  0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\\n  0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\\n  0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\\n  0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\\n  \\vdots &amp; &amp; &amp; \\vdots \\\\\n  N_{max} &amp; N_{max} &amp; \\overline{C}_{N_{max}, N_{max}} &amp; \\sigma_{\\overline{C}_{N_{max}, N_{max}}} \\\\\n\\begin{bmatrix}\n</code></pre>"},{"location":"convert_data_formats/#left-c-backslash-s-right-format","title":"\\(\\left | C \\backslash S \\right |\\)-format","text":"<p>This is another well known arrangement of Spherical Harmonic coefficients. This is a square matrix of size \\(n_{max}, n_{max}\\).</p> <p>The lower traingular terms are made of the cosine terms</p>"},{"location":"convert_data_formats/#left-s-c-right-backslash-format","title":"\\(\\left / S | C \\right \\backslash\\)-format","text":"<p>This is yet another popular format where the sine-coefficients are flipped from left to right, to obtain a triangular arrangement which is completed by zeros.</p> <p>The following figure illustrates the  \\(\\left | C \\backslash S \\right |\\) and  \\(\\left / S | C \\right \\backslash\\) format respectively.</p> <p></p>"},{"location":"convert_data_formats/#pyshbundle.cs2sc.cs2sc","title":"<code>cs2sc(field)</code>","text":"<p>converts the square (L+1)x(L+1) matrix 'field', containing spherical harmonics coefficients in |C\\S| storage format into a  rectangular (L+1)x(2L+1) matrix in  /S|C\\ format.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>ndarray</code> <p>the square (L+1)x(L+1) numpy matrix field , containing        spherical harmonics coefficients in |C\\S| storage format</p> required <p>Returns:</p> Type Description <p>numpy.ndarray: Rectangular (L+1)x(2L+1) numpy matrix in  /S|C\\ format</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>Input neither in cs nor in sc format</p> Todo <ul> <li>Rather use TypeError instead of base Exception</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sc_shcoeff = cs2sc(cs_shcoeff)\nTO DO: write the output\n</code></pre> Source code in <code>pyshbundle/cs2sc.py</code> <pre><code>def cs2sc(field):\n    \"\"\"converts the square (L+1)x(L+1) matrix 'field', containing\n    spherical harmonics coefficients in |C\\S| storage format into a \n    rectangular (L+1)x(2L+1) matrix in  /S|C\\ format.\n\n    Args:\n        field (np.ndarray): the square (L+1)x(L+1) numpy matrix field , containing\n                   spherical harmonics coefficients in |C\\S| storage format\n\n    Returns:\n        numpy.ndarray: Rectangular (L+1)x(2L+1) numpy matrix in  /S|C\\ format\n\n    Raises:\n        TypeError: Input neither in cs nor in sc format\n\n    Todo:\n        + Rather use TypeError instead of base Exception\n\n    Examples:\n        &gt;&gt;&gt; sc_shcoeff = cs2sc(cs_shcoeff)\n        TO DO: write the output\n    \"\"\"\n    rows = len(field)\n    cols = len(field[0])\n\n    if (rows != cols) and (cols != 2*rows - 1):\n        raise TypeError(\"Input neither in cs nor in sc format\")\n    elif cols == 2*rows - 1:\n        sc = field\n    else:\n        c    = numpy.tril(field)\n        ut   = numpy.triu(field)\n        i = numpy.identity(rows)\n        i = 1-i\n        s    = numpy.fliplr(numpy.transpose(numpy.multiply(ut, i, )))\n        sc   = numpy.concatenate((s[:,1:rows], c), axis=1)\n\n    return(sc)\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.sc2cs.sc2cs","title":"<code>sc2cs(field)</code>","text":"<p>converts the rectangular \\((L+1)         imes (2L+1)\\) matrix FIELD, containing spherical harmonics coefficients in /S|C\\ storage format into a  square (L+1)x(L+1) matrix in |C\\S| format.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>ndarray</code> <p>the rectangular (L+1)x(2L+1) matrix FIELD, containing spherical harmonics coefficients in /S|C\\ storage format</p> required <p>Returns:</p> Name Type Description <code>cs</code> <code>ndarray</code> <p>square (L+1)x(L+1) matrix in |C\\S| format</p> References <p>See the SHBundle docs or PySHBundle docs for more info about SH coeff. storage and retrival formats being implementd.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cs_fmt = sc2cs(field)\nTO DO: show suitable output\n</code></pre> Source code in <code>pyshbundle/sc2cs.py</code> <pre><code>def sc2cs(field):\n    \"\"\"converts the rectangular $(L+1) \\times (2L+1)$ matrix FIELD, containing\n    spherical harmonics coefficients in /S|C\\ storage format into a \n    square (L+1)x(L+1) matrix in |C\\S| format.\n\n    Parameters:\n        field (numpy.ndarray()):\n            the rectangular (L+1)x(2L+1) matrix FIELD, containing\n            spherical harmonics coefficients in /S|C\\ storage format\n\n    Returns: \n        cs (numpy.ndarray): \n            square (L+1)x(L+1) matrix in |C\\S| format\n\n    References:\n        See the SHBundle docs or PySHBundle docs for more info about SH coeff. storage and retrival formats being implementd.\n\n    Examples:\n        &gt;&gt;&gt; cs_fmt = sc2cs(field)\n        TO DO: show suitable output\n    \"\"\"\n\n    rows = len(field)\n    cols = len(field[0])\n\n    if (rows!=cols) and (cols!=2*rows - 1):\n        sc2cs.exit(\"Input neither in cs nor in sc format\")\n    elif cols == rows:\n        cs = field\n    else:\n        c    = field[:, rows-1:cols]\n        st   = numpy.transpose(numpy.fliplr(field[:, 0:rows-1]))\n        z    = numpy.zeros([1,rows])\n        s    = numpy.concatenate((st, z), axis=0)\n        cs   = numpy.add(c, s)\n\n    return(cs)\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.clm2cs.clm2cs","title":"<code>clm2cs(data)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>_type_</code> <p>description</p> required Suggestion <p>Instead of printing \"conversion complete\" let's show a progress bar</p> Source code in <code>pyshbundle/clm2cs.py</code> <pre><code>def clm2cs(data):\n    \"\"\"_summary_\n\n    Args:\n        data (_type_): _description_\n\n    Suggestion: \n        Instead of printing \"conversion complete\" let's show a progress bar\n    \"\"\"\n\n    # Load data \n    # data = np.load(path, allow_pickle=True)\n    # data needs to be loaded in numpy format\n\n    # Read variables \n    no_of_years = len(data[0])\n    degree = data[0]\n    clm = data[2]\n    slm = data[3]\n\n    # Count no of months of data \n    month_count =0\n    for i in range(0,len(data[0]),1):\n        month_count= month_count+len(data[0][i])/4750\n    # clm &gt;&gt;&gt; cs \n    month = 0\n    Lmax = degree[0][-1]\n    cs_mat = np.zeros([int(month_count),Lmax+1,Lmax+1])\n    for year in range(0,no_of_years,1):\n        for tile in range(0,int(len(clm[year])/4752),1):\n            i,j = 0,0 \n            for index1 in range(2,Lmax+1,1):\n                for index2 in range(0,index1+1,1):\n                    cs_mat[month,index1,index2] = clm[year][i + tile*4752]\n                    i = i + 1\n            for index3 in range(2,Lmax+1,1):\n                for index4 in range(0,index3,1):\n                    cs_mat[month,index4,index3] = slm[year][j+1 +tile*4752]\n                    j = j + 1\n                j = j + 1\n            month = month + 1\n    print('Conversion into clm format complete')        \n    #np.save('/path/SH_coeff_cs.npy', cs_mat)\n    return cs_mat\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.clm2cs.clm2cs_new","title":"<code>clm2cs_new(data_mat, lmax, sigma_flag=False)</code>","text":"<p>Converts the format from CLM to |C\\S| Under the hood uses the <code>clm2sc</code> and <code>sc2cs</code> function</p> <p>Parameters:</p> Name Type Description Default <code>data_mat</code> <code>ndarray</code> <p>list containing [degree;  order; clm; slm; delta clm; delta slm; start data; end date]</p> required <code>lmax</code> <code>int</code> <p>Max Degree of the spherical harmonic expansion</p> required <code>sigma_flag</code> <code>boolean</code> <p>Flag to return the standard deviation data in |C\\S| format or not. Defaults to False</p> <code>False</code> <p>Returns:</p> Type Description <p>numpy.ndarray: Spherical Harmonic Coefficients in |C\\S| format</p> Source code in <code>pyshbundle/clm2cs.py</code> <pre><code>def clm2cs_new(data_mat: np.ndarray, lmax: int, sigma_flag=False):\n    \"\"\"Converts the format from CLM to |C\\S|\n    Under the hood uses the `clm2sc` and `sc2cs` function\n\n    Args:\n        data_mat (numpy.ndarray): list containing [degree;  order; clm; slm; delta clm; delta slm; start data; end date]\n        lmax (int): Max Degree of the spherical harmonic expansion\n        sigma_flag (boolean): Flag to return the standard deviation data in |C\\S| format or not. Defaults to False\n\n    Returns:\n        numpy.ndarray: Spherical Harmonic Coefficients in |C\\S| format\n\n    \"\"\"\n    if sigma_flag:\n        sc_mat, dev_sc = clm2sc.clm2sc(data_mat=data_mat, lmax=lmax, sigma_flag=True)\n        return sc2cs.sc2cs(sc_mat), sc2cs.sc2cs(dev_sc)\n    else:\n        sc_mat = clm2sc.clm2sc(data_mat=data_mat, lmax=lmax, sigma_flag=False)\n        return sc2cs.sc2cs(sc_mat)\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.clm2sc.clm2sc","title":"<code>clm2sc(data)</code>","text":"<p>Converts the spherical harmonic coefficients from clm format to /S|C\\ format</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list</code> <p>list containing [degree;  order; clm; slm; delta clm; delta slm; start data; end date]</p> required <p>Returns:</p> Type Description <p>np.ndarray: Spherical Harmonic Coefficients in /S|C\\ format [[files or months]; [2-D matrix of /S|C\\ format]]</p> <p>np.ndarray: Standard Deviations of correcponding Spherical Harmonic Coefficients in /S|C\\ format [[files or months]; [2-D matrix of /S|C\\ format]]</p> References <p>Refer to the SHBundle or PySHBundle docs for the different data storage and retrival formats.</p> Source code in <code>pyshbundle/clm2sc.py</code> <pre><code>def clm2sc(data):\n    \"\"\"Converts the spherical harmonic coefficients from clm format to /S|C\\ format\n\n    Args:\n        data (list): list containing [degree;  order; clm; slm; delta clm; delta slm; start data; end date]\n\n    Returns:\n        np.ndarray: Spherical Harmonic Coefficients in /S|C\\ format [[files or months]; [2-D matrix of /S|C\\ format]]\n        np.ndarray: Standard Deviations of correcponding Spherical Harmonic Coefficients in /S|C\\ format [[files or months]; [2-D matrix of /S|C\\ format]]\n\n    References:\n        Refer to the SHBundle or PySHBundle docs for the different data storage and retrival formats.\n    \"\"\"\n    # import pickle\n    # data=np.load(\"/path/saved_as-num.npy\",allow_pickle=True)\n    # with open(\"/path/saved_as_num\", \"rb\") as pk:\n    #     data=pickle.load(pk)\n\n    # Read variables \n    no_of_years = len(data[0])\n    degree = data[0]\n    clm = data[2]\n    slm = data[3]\n    clm_std_dev = data[4]\n    slm_std_dev = data[5]\n\n    Lmax = degree[0][-1]\n    degree_order = int((Lmax+1) * (Lmax+2)/2)\n    # Count no of months of data \n    month_count = 0\n    for i in range(0, len(data[0]), 1):\n        month_count = month_count+round(len(data[0][i])/degree_order)\n\n    # clm &gt;&gt;&gt; sc \n    month = 0\n    sc_mat = np.zeros([month_count, Lmax+1, 2*Lmax + 2])\n    dev_sc_mat = np.zeros([month_count, Lmax+1, 2*Lmax + 2])\n    for year in range(0, no_of_years, 1):\n        for tile in range(0,int(len(degree[year])/degree_order), 1):\n            i = 0\n            for index1 in range(0,Lmax+1, 1):\n                for index2 in range(0,index1+1, 1):\n\n                    sc_mat[month, index1, Lmax-index2] = slm[year][i + tile*degree_order]\n                    sc_mat[month, index1, Lmax+index2+1] = clm[year][i + tile*degree_order]\n\n                    dev_sc_mat[month, index1, Lmax-index2] = slm_std_dev[year][i + tile*degree_order]\n                    dev_sc_mat[month, index1, Lmax+index2+1] = clm_std_dev[year][i + tile*degree_order]\n\n                    i = i + 1\n            month = month + 1\n\n    # delete order 0 column\n    sc_mat = np.delete(sc_mat, Lmax, 2)\n    dev_sc_mat = np.delete(dev_sc_mat, Lmax, 2)\n    print('Conversion into clm format complete')\n    return sc_mat, dev_sc_mat\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.clm2sc.clm2sc_new","title":"<code>clm2sc_new(data_mat, lmax, sigma_flag=False)</code>","text":"<p>Converts the spherical harmonic coefficients from clm format to /S|C\\ format</p> <p>Parameters:</p> Name Type Description Default <code>data_mat</code> <code>ndarray</code> <p>list containing [degree;  order; clm; slm; delta clm; delta slm; start data; end date]</p> required <code>lmax</code> <code>int</code> <p>Max Degree of the spherical harmonic expansion</p> required <code>sigma_flag</code> <code>boolean</code> <p>Flag to return the standard deviation data in /S|C\\ format or not. Defaults to False</p> <code>False</code> <p>Returns:</p> Type Description <p>numpy.ndarray: Spherical Harmonic Coefficients in /S|C\\ format</p> References <p>Refer to the SHBundle or PySHBundle docs for the different data storage and retrival formats.</p> Source code in <code>pyshbundle/clm2sc.py</code> <pre><code>def clm2sc_new(data_mat: np.ndarray, lmax: int, sigma_flag=False):\n    \"\"\"Converts the spherical harmonic coefficients from clm format to /S|C\\ format\n\n    Args:\n        data_mat (numpy.ndarray): list containing [degree;  order; clm; slm; delta clm; delta slm; start data; end date]\n        lmax (int): Max Degree of the spherical harmonic expansion\n        sigma_flag (boolean): Flag to return the standard deviation data in /S|C\\ format or not. Defaults to False\n\n    Returns:\n        numpy.ndarray: Spherical Harmonic Coefficients in /S|C\\ format\n\n    References:\n        Refer to the SHBundle or PySHBundle docs for the different data storage and retrival formats.\n\n    \"\"\"\n\n\n\n    sc_mat = np.zeros((lmax+1, 2*lmax + 2))\n    dev_sc_mat = np.zeros((lmax+1, 2*lmax + 2))\n\n    # as per the convention\n    clm = data_mat[:, 2]\n    slm = data_mat[:, 3]\n    clm_std_dev = data_mat[:, 4]\n    slm_std_dev = data_mat[:, 5]\n\n    i = 0\n    for index1 in range(0,lmax+1, 1):\n        for index2 in range(0,index1+1, 1):\n\n            sc_mat[index1, lmax-index2] = slm[i]\n            sc_mat[index1, lmax+index2+1] = clm[i]\n\n            dev_sc_mat[index1, lmax-index2] = slm_std_dev[i]\n            dev_sc_mat[index1, lmax+index2+1] = clm_std_dev[i]\n\n            i = i + 1\n\n    sc_mat = np.delete(sc_mat, lmax, 1)\n    dev_sc_mat = np.delete(dev_sc_mat, lmax, 1)\n\n    if sigma_flag:\n        return sc_mat, dev_sc_mat\n    else:\n        return sc_mat\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.klm2sc.klm2sc","title":"<code>klm2sc(data)</code>","text":"<p>Converts the spherical harmonic coefficients from klm format to /S|C\\ format</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list</code> <p>list containing [degree;  order; clm; slm; delta clm; delta slm; start data; end date]</p> required <p>Returns:</p> Type Description <p>np.ndarray: Spherical Harmonic Coefficients in /S|C\\ format [[files or months]; [2-D matrix of /S|C\\ format]]</p> <p>np.ndarray: Standard Deviations of correcponding Spherical Harmonic Coefficients in /S|C\\ format [[files or months]; [2-D matrix of /S|C\\ format]]</p> Source code in <code>pyshbundle/klm2sc.py</code> <pre><code>def klm2sc(data):\n    \"\"\"Converts the spherical harmonic coefficients from klm format to /S|C\\ format\n\n    Args:\n        data (list): list containing [degree;  order; clm; slm; delta clm; delta slm; start data; end date]\n\n    Returns:\n        np.ndarray: Spherical Harmonic Coefficients in /S|C\\ format [[files or months]; [2-D matrix of /S|C\\ format]]\n        np.ndarray: Standard Deviations of correcponding Spherical Harmonic Coefficients in /S|C\\ format [[files or months]; [2-D matrix of /S|C\\ format]]\n    \"\"\"\n    # import pickle\n    # with open(\"/path/saved_as_num\", \"rb\") as pk:\n    #     data=pickle.load(pk)\n\n    ''' Read variables '''\n    no_of_years = len(data[0])\n    degree = data[0]\n    clm = data[2]\n    slm = data[3]\n    clm_std_dev = data[4]\n    slm_std_dev = data[5]\n\n    lmax=degree[0][-1]\n    degree_order=int((lmax+1)*(lmax+2)/2)\n\n    ''' Count no of months of data '''\n    month_count =0\n    for i in range(0,len(data[0]),1):\n        month_count= month_count+round(len(data[0][i])/degree_order)\n\n    ''' klm &gt;&gt;&gt; sc '''\n    month = 0\n    sc_mat = np.zeros([month_count,lmax+1,2*lmax+2])\n    dev_sc_mat = np.zeros((month_count, lmax+1, 2*lmax + 2))\n\n    for year in range(0,no_of_years,1):\n        index2 =0\n        for tile in range(0,int(len(clm[year])/degree_order),1):  \n            for index1 in range(0,lmax+1,1):\n                sc_mat[month,index1:,lmax-index1] = slm[year][(index2):(index2+lmax-index1+1)]\n                sc_mat[month,index1:,index1+lmax] = clm[year][(index2):(index2+lmax-index1+1)]\n\n                dev_sc_mat[month,index1:,lmax-index1] = slm_std_dev[year][(index2):(index2+lmax-index1+1)]\n                dev_sc_mat[month,index1:,index1+lmax] = clm_std_dev[year][(index2):(index2+lmax-index1+1)]\n\n\n\n                #print(month,'\\t',index1,'\\t',Lmax-index1,'\\t',year,'\\t',index2,'\\t',index2+Lmax-index1+1)\n                index2 = index2+lmax-index1+1\n            month=month+1\n\n    sc_mat=np.delete(sc_mat,lmax,axis=2)\n    dev_sc_mat=np.delete(dev_sc_mat,lmax,axis=2)\n\n    print('Conversion into clm format complete')\n    return sc_mat, dev_sc_mat\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.klm2sc.klm2sc_new","title":"<code>klm2sc_new(data_mat, lmax, sigma_flag=False)</code>","text":"<p>Converts the spherical harmonic coefficients from klm format to /S|C\\ format</p> <p>Parameters:</p> Name Type Description Default <code>data_mat</code> <code>ndarray</code> <p>A 2-D matrix(numpy ndarray)</p> required <code>lmax</code> <code>int</code> <p>maximum degree of spherical harmonic expansion</p> required <code>sigma_flag</code> <code>bool</code> <p>Flag to return the associated standard deviation values. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>np.ndarray: Spherical Harmonic Coefficients or/and associated standard deviations in /S|C\\ format</p> Source code in <code>pyshbundle/klm2sc.py</code> <pre><code>def klm2sc_new(data_mat: np.ndarray, lmax: int, sigma_flag=False):\n    \"\"\"Converts the spherical harmonic coefficients from klm format to /S|C\\ format\n\n    Args:\n        data_mat (np.ndarray): A 2-D matrix(numpy ndarray)\n        lmax (int): maximum degree of spherical harmonic expansion\n        sigma_flag (bool, optional): Flag to return the associated standard deviation values. Defaults to False.\n\n    Returns:\n        np.ndarray: Spherical Harmonic Coefficients or/and associated standard deviations in /S|C\\ format\n    \"\"\"\n    sc_mat = np.zeros((lmax+1, 2*lmax + 2))\n    dev_sc_mat = np.zeros((lmax+1, 2*lmax + 2))\n    clm = data_mat[:, 2]\n    slm = data_mat[:, 3]\n    clm_std_dev = data_mat[:, 4]\n    slm_std_dev = data_mat[:, 5]\n\n    # first place the slm and then clm\n    index2 =0\n    for index1 in range(0,lmax+1,1):\n        sc_mat[index1:, lmax-index1] = slm[(index2):(index2 + lmax-index1+1)]\n        sc_mat[index1:, index1+lmax] = clm[(index2):(index2 + lmax-index1+1)]\n\n        dev_sc_mat[index1:, lmax-index1] = slm_std_dev[(index2):(index2 + lmax-index1+1)]\n        dev_sc_mat[index1:, index1+lmax] = clm_std_dev[(index2):(index2 + lmax-index1+1)]\n\n        index2 = index2 + lmax-index1+1\n\n    sc_mat=np.delete(sc_mat,lmax,axis=1)\n    dev_sc_mat=np.delete(dev_sc_mat,lmax,axis=1)\n\n    if sigma_flag:\n        return sc_mat, dev_sc_mat\n    else: \n        return sc_mat\n</code></pre>"},{"location":"convert_data_formats/#reference","title":"Reference","text":"<ul> <li>Nico Sneeuw, Matthias Weigelt, Markus Antoni, Matthias Roth, Balaji Devaraju, et. al. (2021). SHBUNDLE 2021. http://www.gis.uni-stuttgart.de/research/projects/Bundles.</li> </ul>"},{"location":"core_functionality/","title":"Core functionality","text":"<p>This module has both Spherical Harmonics Analysis and Spherical Harmonics Synthesis</p>"},{"location":"core_functionality/#spherical-harmonic-analysis-and-synthesis","title":"Spherical Harmonic Analysis and Synthesis","text":""},{"location":"core_functionality/#pyshbundle.gsha.gsha","title":"<code>gsha(f, method, grid=None, lmax=-9999)</code>","text":"<p>GSHA - Global Spherical Harmonic Analysis</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>ndarray</code> <p>global field of size \\((l_{max} + 1) * 2 * l_{max}\\) or \\(l_{max} * 2 * l_{max}\\)</p> required <code>method</code> <code>str</code> <p>method to be used</p> required <code>grid</code> <code>str</code> <p>choose between 'block' or 'cell'. Defaults to None.</p> <code>None</code> <code>lmax</code> <code>int</code> <p>maximum degree of development. Defaults to -9999.</p> <code>-9999</code> <p>Returns:</p> Type Description <p>np.ndarray: Clm, Slm in |C\\S| format</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>grid argument can only be 'block' or 'cell'</p> <code>ValueError</code> <p>Grid type entered is not right</p> <code>TypeError</code> <p>Invalid size of matrix F</p> <code>TypeError</code> <p>GRID and METHOD must be strings</p> <code>ValueError</code> <p>2nd Neumann method ONLY on a ''neumann''/''gauss'' GRID'</p> <code>ValueError</code> <p>Block mean method ONLY on a ''block''/''cell'' GRID</p> <code>ValueError</code> <p>Maximum degree of development is higher than number of rows of input.</p> Uses <p><code>plm</code>, <code>neumann</code>, <code>iplm</code>, <code>sc2cs</code></p> Source code in <code>pyshbundle/gsha.py</code> <pre><code>def gsha(f, method: str, grid: str = None, lmax: int = -9999):\n    \"\"\" GSHA - Global Spherical Harmonic Analysis\n\n    Args:\n        f (np.ndarray): global field of size $(l_{max} + 1) * 2 * l_{max}$ or $l_{max} * 2 * l_{max}$\n        method (str): method to be used\n        grid (str, optional): choose between 'block' or 'cell'. Defaults to None.\n        lmax (int, optional): maximum degree of development. Defaults to -9999.\n\n    Returns:\n        np.ndarray: Clm, Slm in |C\\S| format\n\n    Raises:\n        ValueError: grid argument can only be 'block' or 'cell'\n        ValueError: Grid type entered is not right\n        TypeError: Invalid size of matrix F\n        TypeError: GRID and METHOD must be strings\n        ValueError: 2nd Neumann method ONLY on a ''neumann''/''gauss'' GRID'\n        ValueError: Block mean method ONLY on a ''block''/''cell'' GRID\n        ValueError: Maximum degree of development is higher than number of rows of input.\n\n    Uses:\n        `plm`, `neumann`, `iplm`, `sc2cs`\n    \"\"\"\n    rows, cols = f.shape\n\n    if cols == 2 * rows: #Check conditions\n        if lmax == -9999:\n            lmax = rows\n\n        if grid == None:\n            grid = 'block'\n\n        if (grid != 'block') and (grid != 'cell'):\n            raise ValueError(\"Your GRID variable should be either block or cell\")\n\n        n = rows\n        dt = 180 / n\n        theta = np.arange(dt/2, 180+(dt/4), dt)\n        lam = np.arange(dt/2, 360+(dt/4), dt)\n\n    elif cols == 2 * rows - 2:\n        if lmax == -9999:\n            lmax = rows - 1\n        if grid == None:\n            grid = 'pole'\n\n        n = rows - 1\n        dt = 180 / n\n\n        if (grid == 'pole') or (grid == 'mesh'):                   \n            theta = np.arange(0, 180+(dt/4), dt)\n            lam = np.arange(0, 360+(dt/4) - dt, dt)\n        elif (grid == 'neumann') or (grid == 'gauss'): \n        # gw, gx = neumann(n+1) #For some reason, grule does not work for even values\n            gw, gx = neumann.neumann(n)\n            theta = np.arccos(np.flipud(gx)) * 180 / np.pi\n            lam = np.arange(0, 360+(dt/4)-dt, dt)\n\n            if len(gw.shape) == 1:\n                gw = gw.reshape(gw.shape[0],1)\n\n            if len(gx.shape) == 1:\n                gx = gx.reshape(gx.shape[0],1)\n        else:\n            raise ValueError(\"Grid type entered is not right\")\n    else:\n        raise TypeError(\"Invalid size of matrix F\")\n\n    theRAD = theta * np.pi / 180\n    # if len(theRAD.shape) == 1:\n    # theRAD = theRAD.reshape(theRAD.shape[0],1)\n\n\n    # further diagnostics\n\n    if (type(grid) != str) or (type(method) != str):\n        raise TypeError(\"GRID and METHOD must be strings.\")\n\n    if (method == 'snm') and ((grid != 'neumann') and (grid != 'gauss')):\n        raise ValueError('2nd Neumann method ONLY on a ''neumann''/''gauss'' GRID')\n\n    if (method == 'mean') and ((grid != 'block') and (grid != 'cell')):\n        raise ValueError('Block mean method ONLY on a ''block''/''cell'' GRID')\n\n    if lmax &gt; n:\n        raise ValueError('Maximum degree of development is higher than number of rows of input.')\n\n    # Reshape variables as required\n\n    if len(lam.shape) == 1:\n        lam = lam.reshape(1,lam.shape[0])\n\n    # Init\n\n    L = n\n    clm = np.zeros((L+1, L+1), dtype='longdouble')\n    slm = np.zeros((L+1, L+1), dtype='longdouble')\n\n\n    # First step of analysis\n\n    m = np.arange(L+1).reshape(1,L+1)\n    c = np.cos((lam.T @ m) * np.pi/180)\n    s = np.sin((lam.T @ m) * np.pi/180)\n\n\n    # % preserving the orthogonality (except for 'mean' case)\n    # % we distinguish between 'block' and 'pole' type grids (in lambda)\n\n    if (grid == 'block') or (grid == 'cell'):\n        if method == 'mean':\n            dl = dt\n            c[:,0] = dl / 360\n            m = np.arange(1, L+1)\n            ms = 2 / m * np.sin(m * dl/2 * np.pi/180) / np.pi\n            c[:,1:(L+1)+1] = c[:,1:(L+1)+1] * ms  \n            s[:,1:(L+1)+1] = s[:,1:(L+1)+1] * ms\n\n        else:\n            c = c/L\n            s = s/L\n            c[:,0] = c[:,1]/2\n            s[:,L] = s[:,L]/2\n            c[:,L] = np.zeros(2*n)\n            s[:,0] = np.zeros(2*n)\n    else:\n        c = c/L\n        s = s/L\n        c[:,[0, L]] = c[:,[0, L]]/2\t\n        s[:,[0, L]] = np.zeros((2*n,2))\t  \n\n\n    a = f @ c\n    b = f @ s    \n\n    # Second step of analysis: Clm and Slm\n\n    if method == 'ls':\n        for m in range(L+1):\n#            l = np.arange(m,L+1)\n            l = np.arange(m,L+1).reshape(L+1-m, 1)\n            l = l.T\n\n            p = plm(l,m,theRAD, 3, 1)\n            p = p[:,:,0]\n            ai = a[:, m]\n            bi = b[:, m]\n\n            clm[m+1:L+2, m+1] = linalg.lstsq(p, ai)\n            slm[m+1:L+2, m+1] = linalg.lstsq(p, bi)\n\n\n    elif method == 'aq': #Approximate Quadrature\n        si = np.sin(theRAD)\n        si = 2 * si / np.sum(si)\n\n        for m in range(L+1):\n            l = np.arange(m, L+1).reshape(L+1-m, 1)\n            l = l.T\n\n            p = plm(l,m,theRAD, 3, 1)\n\n            ai = a[:, m]\n            bi = b[:, m]\n\n            clm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (si * ai)\n            slm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (si * bi)\n\n    elif method == 'fnm': #1st Neumann method (exact upto L/2)\n        w = neumann.neumann(np.cos(theRAD))\n\n        for m in range(L+1):\n            l = np.arange(m, L+1).reshape(L+1-m, 1)\n            l = l.T\n\n            p = plm(l,m,theRAD, 3, 1)\n\n            ai = a[:, m]\n            bi = b[:, m]\n\n            clm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (w * ai)\n            slm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (w * bi)\n\n    elif method == 'snm': #2nd Neumann method (exact)\n        for m in range(L+1):\n            l = np.arange(m, L+1).reshape(L+1-m, 1)\n            l = l.T\n\n            p = plm(l,m,theRAD, 3, 1)\n\n            ai = a[:, m]\n            bi = b[:, m]\n\n            clm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (gw * ai)\n            slm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (gw * bi)\n\n    elif method == 'mean':\n        for m in range(L+1):\n            print(m)\n            #l = np.arange(m,L+1).reshape(L+1-m,1)\n            #l = l.T\n\n\n            l = np.array([np.arange(m,L+1, 1)])\n        # l = np.array([[m]])\n\n            p = iplm(l,m,theRAD)\n        # p = p[:,-1]\n            ai = a[:, m]\n            bi = b[:, m]\n\n            clm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ ai\n            slm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ bi\n\n    # Write the coefficients Clm &amp; Slm in |C\\S| format\n\n    slm = np.fliplr(slm)\n    cs = sc2cs(np.concatenate((slm[:, np.arange(L)], clm), axis = 1))\n    cs = cs[:int(lmax+1), :int(lmax+1)]\n\n\n    # np.save('/path/csRb.npy',cs)\n\n    return cs\n</code></pre>"},{"location":"core_functionality/#pyshbundle.gshs.gshs","title":"<code>gshs(field, quant='none', grd='mesh', n=-9999, h=0, jflag=1)</code>","text":"<p>GSHS - Global Spherical Harmonic Synthesis</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>_type_</code> <p>set of SH coefficients, either in SC-triangle or CS-square format</p> required <code>quant</code> <code>str</code> <p>defining the field quantity. Defaults to 'none'.</p> <code>'none'</code> <code>grd</code> <code>str</code> <p>defining the grid. Defaults to 'mesh'.</p> <code>'mesh'</code> <code>n</code> <code>int</code> <p>description. Defaults to -9999.</p> <code>-9999</code> <code>h</code> <code>int</code> <p>description. Defaults to 0.</p> <code>0</code> <code>jflag</code> <code>int</code> <p>description. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>f</code> <code>ndarray</code> <p>the global field</p> <p>theRAD (): vector of co-latitudes [rad]</p> <p>lamRAD (): vector of longitudes [rad]</p> <p>Raises:</p> Type Description <code>Exception</code> <p>Check format of the field</p> <code>Exception</code> <p>n must be scalar</p> <code>Exception</code> <p>n must be integer</p> <code>Exception</code> <p>Grid argument must be string</p> <code>Exception</code> <p>description</p> Uses <p><code>cs2sc</code>, <code>normalklm</code>, <code>plm</code>, <code>eigengrav</code>, <code>ispec</code></p> Todo <ul> <li>Change general exceptions to specific and descriptive built-in ones</li> <li>using the not and then check is not always advisable</li> <li>Check how to document valid options</li> </ul> Source code in <code>pyshbundle/gshs.py</code> <pre><code>def gshs(field, quant = 'none', grd = 'mesh', n = -9999, h = 0, jflag = 1):\n    \"\"\"GSHS - Global Spherical Harmonic Synthesis\n\n    Args:\n        field (_type_): set of SH coefficients, either in SC-triangle or CS-square format\n        quant (str, optional): defining the field quantity. Defaults to 'none'.\n        grd (str, optional): defining the grid. Defaults to 'mesh'.\n        n (int, optional): _description_. Defaults to -9999.\n        h (int, optional): _description_. Defaults to 0.\n        jflag (int, optional): _description_. Defaults to 1.\n\n    Returns:\n        f (np.ndarray): the global field\n        theRAD (): vector of co-latitudes [rad]\n        lamRAD (): vector of longitudes [rad]\n\n    Raises:\n        Exception: Check format of the field\n        Exception: n must be scalar\n        Exception: n must be integer\n        Exception: Grid argument must be string\n        Exception: _description_\n\n    Uses:\n        `cs2sc`, `normalklm`, `plm`, `eigengrav`, `ispec`\n\n    Todo: \n        * Change general exceptions to specific and descriptive built-in ones\n        + using the not and then check is not always advisable\n        + Check how to document valid options\n    \"\"\"\n\n    wd = getcwd()\n    chdir(wd)\n\n    rows, cols = field.shape\n\n    if rows == cols:                    #field in CS-format \n        lmax = rows - 1\n        field = cs2sc.cs2sc(field)\n    elif cols - 2 * rows == -1:         #field in SC-format already\n        lmax = rows - 1\n    else:\n        raise Exception(\"Check format of the field\")\n\n    if n == -9999:                      #(no value of n is input) -&gt; set n = lmax\n        n = lmax\n\n    if not np.isscalar(n):\n        raise Exception(\"n must be scalar\")\n\n    if not np.issubdtype(type(n), np.integer):\n        raise Exception(\"n must be integer\")\n\n    if not type(grd) == str:\n        raise Exception(\"Grid argument must be string\")\n\n    grd = grd.lower()\n\n\n\n    #Grid Definition\n    dt = np.pi/n\n\n    if grd == 'pole' or grd == 'mesh':\n        theRAD = np.arange(0, np.pi+dt*0.5, dt, dtype='longdouble')\n        lamRAD = np.arange(0, 2*np.pi, dt, dtype='longdouble')\n    elif grd == 'block' or grd == 'cell':\n        theRAD = np.arange(dt/2, np.pi + dt*0.5, dt, dtype='longdouble')\n        lamRAD = np.arange(dt/2, 2*np.pi + dt*0.5, dt, dtype='longdouble')\n    else:\n        raise Exception(\"Incorrect grid type input\")\n\n    nlat = len(theRAD)\n    nlon = len(lamRAD)\n\n\n\n#    % -------------------------------------------------------------------------\n#% Preprocessing on the coefficients: \n#%    - subtract reference field (if jflag is set)\n#%    - specific transfer\n#%    - upward continuation\n#% -------------------------------------------------------------------------\n\n    if jflag:\n        field = field - cs2sc.cs2sc(normalklm.normalklm(lmax+1))\n\n    l = np.arange(0, lmax+1)\n    transf = np.array([eigengrav.eigengrav(lmax, quant, h)])[0, :, :].T\n\n    field = field * np.matmul(transf, np.ones((1, 2*lmax+1)), dtype='longdouble')\n\n\n    '''\n    % -------------------------------------------------------------------------\n% Size declarations and start the waitbar:\n% Note that the definition of dlam causes straight zero-padding in case N &gt; L.\n% When N &lt; L, there will be zero-padding up to the smallest integer multiple\n% of N larger than L. After the Fourier transformation (see below), the\n% proper samples have to be picked out, with stepsize dlam.\n% -------------------------------------------------------------------------\n    '''\n\n    dlam = int(np.ceil(lmax/n))             #longitude step size\n    abcols = dlam*n + 1                     #columns required in A and B\n    a = np.zeros((nlat, int(abcols)), dtype='longdouble')\n    b = np.zeros((nlat, int(abcols)), dtype='longdouble')\n\n\n\n    m = 0\n    c = field[m:lmax+1, lmax+m] \n    l = np.array([np.arange(m,lmax+1)])\n    p = plm.plm(l, m, theRAD, nargin = 3, nargout = 1)[:,:,0]\n    a[:, m] = np.dot(p,c) \n    b[:, m] = np.zeros(nlat) \n\n\n\n    for m in range(1,lmax+1,1):\n        c = field[m:lmax+1,lmax+m]\n        s = field[m:lmax+1,lmax-m]\n\n        l = np.array([np.arange(m,lmax+1)])\n        p = plm.plm(l, m, theRAD, nargin = 3, nargout = 1)[:,:,0]\n        a[:, m] = np.dot(p,c)\n        b[:, m] = np.dot(p,s)\n\n    del field\n    '''\n     -------------------------------------------------------------------------\n The second synthesis step consists of an inverse Fourier transformation\n over the rows of a and b. \n In case of 'block', the spectrum has to be shifted first.\n When no zero-padding has been applied, the last b-coefficients must be set to\n zero. Otherwise the number of longitude samples will be 2N+1 instead of 2N.\n For N=L this corresponds to setting SLL=0!\n -------------------------------------------------------------------------\n    '''\n\n    if grd =='block' or grd == 'cell': \n      m      = np.arange(0,abcols,1)\n      cshift = np.array([np.ones(nlat)], dtype='longdouble').T * np.array([np.cos(m*np.pi/2/n)], dtype='longdouble');\t# cshift/sshift describe the \n      sshift = np.array([np.ones(nlat)], dtype='longdouble').T * np.array([np.sin(m*np.pi/2/n)], dtype='longdouble');\t# half-blocksize lambda shift.\n      atemp  =  cshift*a + sshift*b\n      b      = -sshift*a + cshift*b\n      a      = atemp\n\n\n\n    if np.remainder(n,lmax) == 0:               #Case without zero-padding\n        b[:,abcols-1] = np.zeros(nlat)\n\n    #Code for ispec\n\n    f = ispec.ispec(a.T, b.T).T\n    if dlam &gt; 1: \n        f = f[:,np.arange(1,dlam*nlon+1,dlam)]\n\n    return f, theRAD, lamRAD\n</code></pre>"},{"location":"core_functionality/#intro-to-grace-data-driven-correction","title":"Intro to Grace Data Driven Correction","text":""},{"location":"core_functionality/#pyshbundle.GRACE_Data_Driven_Correction_Vishwakarma.GRACE_Data_Driven_Correction_Vishwakarma","title":"<code>GRACE_Data_Driven_Correction_Vishwakarma(F, cf, GaussianR, basins)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>F</code> <code>_type_</code> <p>a cell matrix with one column containing SH coefficients</p> required <code>cf</code> <code>_type_</code> <p>the column in F that contains SH coefficients from GRACE</p> required <code>GaussianR</code> <code>_type_</code> <p>radius of the Gaussian filter (recommened = 400)</p> required <code>basins</code> <code>_type_</code> <p>mask functions of basin, a cell data format with one             column and each entry is a 360 x 720 matrix with 1 inside the             catchment and 0 outside</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>corrected data-driven time-series (Least Squares fit method)</p> <code>Exception</code> <p>corrected data-driven time-series (shift and amplify method)</p> <code>Exception</code> <p>gaussian filtered GRACE TWS time-series for all the basins.</p> <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Todo <ul> <li>TypeError</li> </ul> Source code in <code>pyshbundle/GRACE_Data_Driven_Correction_Vishwakarma.py</code> <pre><code>def GRACE_Data_Driven_Correction_Vishwakarma(F, cf, GaussianR, basins):\n    \"\"\"_summary_\n\n    Args:\n        F (_type_): a cell matrix with one column containing SH coefficients\n        cf (_type_): the column in F that contains SH coefficients from GRACE\n        GaussianR (_type_): radius of the Gaussian filter (recommened = 400)\n        basins (_type_): mask functions of basin, a cell data format with one\n                        column and each entry is a 360 x 720 matrix with 1 inside the\n                        catchment and 0 outside\n\n    Raises:\n        Exception: corrected data-driven time-series (Least Squares fit method)\n        Exception: corrected data-driven time-series (shift and amplify method)\n        Exception: gaussian filtered GRACE TWS time-series for all the basins.\n\n    Returns:\n        _type_: _description_\n\n    Todo:\n        + TypeError\n    \"\"\"\n    deg = 0.5\n    deg_rad = deg_to_rad(deg)\n\n    x = np.linspace(0, 360-deg, int(360/deg))\n    y = np.linspace(0, 180-deg, int(180/deg))\n    x1 = np.linspace(deg, 360, int(360/deg))\n    y1 = np.linspace(deg, 180, int(180/deg))\n    lambdd,theta = np.meshgrid(x,y)  \n    lambdd1,theta1 = np.meshgrid(x1,y1)\n\n    theta_rad = deg_to_rad(theta)\n    theta1_rad = deg_to_rad(theta1)\n\n    #Areahalfdeg = (6378.137**2)*np.power(10,6)*np.pi/180*(np.multiply(a,b)) #Area matrix\n    Areahalfdeg = (6378.137**2)*(((np.pi/180)*lambdd1) - ((np.pi/180)*lambdd))*(np.sin((np.pi/2) - theta_rad) - np.sin((np.pi/2) - theta1_rad))\n\n    qty = 'water'\n\n    if type(F) != np.ndarray:\n        raise Exception(\"input GRACE field should be in Numpy Ndarray format, please check guidelines\")\n\n\n    if type(basins) != np.ndarray:\n        raise Exception(\"input basin field should be in Numpy NdArray format, please check guidelines\")\n\n\n    r = F.shape[0] #No of entries in F numpy ndarrray\n\n    cid = 1 #number of river catchments\n\n    f = F[:,cf-1:cf]\n    l = f[0][0].shape[0]\n    cfield = f[0][0].shape[1]\n    if cfield == l:\n        flag_cs = 0\n    else:\n        flag_cs = 1\n\n    Weights = gaussian.gaussian(l-1, GaussianR) \n    #gaussian returns weights as a list #gaussian is np.array()\n\n    try: #Broadcase Weights into dimensions\n        filter_ = np.ones([1,(2*(l-1))+1]) * Weights\n    except:\n        w0 = Weights.shape[0]\n        Weights = Weights.reshape(w0,1)\n        filter_ = np.ones([1,(2*(l-1))+1]) * Weights\n\n\n    #SH Synthesis\n    if l == cfield:\n        for m in range(r):\n            if flag_cs == 0:\n                Ft = cs2sc.cs2sc(f[m][0]).astype('longdouble') \n            else:\n                Ft = f[m][0].astype('longdouble') \n\n\n            fFld__, _, _ = gshs.gshs(Ft * filter_, qty, 'cell', int(180/deg), 0, 0) \n            ffFld__, _, _ = gshs.gshs((Ft * filter_ * filter_), qty, 'cell', int(180/deg), 0, 0)\n\n            if m == 0:\n                fFld = np.zeros((r,fFld__.shape[0],fFld__.shape[1]), dtype = 'longdouble') \n                ffFld = np.zeros((r, ffFld__.shape[0], ffFld__.shape[1]), dtype = 'longdouble')\n\n            fFld[m] = fFld__\n            ffFld[m] = ffFld__\n\n        long = 360/deg\n        Area = Areahalfdeg\n    else:\n        raise Exception(\"enter CS coefficients\")\n\n\n\n    #Declaration of size of the vectors:\n    cid = len(basins) #Here basins is a dictionary with each element storing nd array\n    tsleaktotalf = np.zeros([r, cid], dtype = 'longdouble')\n    tsleaktotalff = np.zeros([r, cid], dtype = 'longdouble')\n\n    ftsleaktotal = np.zeros([r, cid], dtype = 'longdouble')\n    fftsleaktotal = np.zeros([r, cid], dtype = 'longdouble')\n\n    lhat = np.zeros([r, cid], dtype = 'longdouble')\n\n    bfDevRegAv = np.zeros([r, cid], dtype = 'longdouble')\n    bbfDevRegAv = np.zeros([r, cid], dtype = 'longdouble')\n\n    FilteredTS = np.zeros([r, cid], dtype = 'longdouble')\n    filfilts = np.zeros([r, cid], dtype = 'longdouble')\n\n    leakage = np.zeros([r, cid], dtype = 'longdouble')\n    leakager = np.zeros([r, cid], dtype = 'longdouble')   \n\n\n\n    for rbasin in range(0, cid):\n        #Get the basin functions ready\n\n        #Basin functions, filtered basin function and transfer function Kappa\n        Rb = basins[rbasin][0] \n        csRb = gsha.gsha(Rb, 'mean', 'block', long/2) \n        csF = cs2sc.cs2sc(csRb[0:l, 0:l]) \n        filRb_ = gshs(csF * filter_, 'none', 'cell', int(long/2), 0, 0) \n        filRb = filRb_[0]\n        kappa = (1-Rb) * filRb\n\n\n\n        fF = np.zeros((fFld__.shape[0],fFld__.shape[1]), dtype = 'longdouble')\n        ffF = np.zeros((fFld__.shape[0],fFld__.shape[1]), dtype = 'longdouble')\n        for m in range(0,r):\n\n\n            fF = np.concatenate((fFld[m,:,int(fF.shape[1]/2):], fFld[m,:,:int(fF.shape[1]/2)]), axis=1)\n            ffF = np.concatenate((ffFld[m,:,int(ffF.shape[1]/2):], ffFld[m,:,:int(ffF.shape[1]/2)]), axis=1)\n            #if False:    \n            if np.isnan(fF[:20,:20]).any(): #if there is a gap in time series, fill it with NaNs\n\n\n                tsleaktotalf[m][rbasin] = np.nan\n                tsleaktotalff[m][rbasin] = np.nan\n                FilteredTS[m][rbasin] = np.nan\n                filfilts[m][0:rbasin] = np.nan\n                bfDevRegAv[m][rbasin] = np.nan\n                bbfDevRegAv[m][0:rbasin] = np.nan\n\n            else:\n                #leakage time series from filtered and twice filtered fields\n                tsleaktotalf[m][rbasin] = np.sum(fF * kappa * Area) / np.sum(Rb * Area)\n                tsleaktotalff[m][rbasin] = np.sum(ffF * kappa * Area) / np.sum(Rb * Area)\n\n                #time series from filtered fields\n                FilteredTS[m][rbasin] = np.sum(fF * Rb * Area) / np.sum(Rb * Area)\n                filfilts[m][rbasin] = np.sum(ffF * Rb * Area) / np.sum(Rb * Area)\n\n                #Deviation integral timeseries\n                bfDevRegAv[m][rbasin] = np.sum((fF * Rb - FilteredTS[m][rbasin]) * filRb * Area) / np.sum(Rb * Area) #working 2022-10-20\n                bbfDevRegAv[m][rbasin] = np.sum((ffF * Rb - filfilts[m][rbasin]) * filRb * Area) / np.sum(Rb * Area)\n                print(m)\n\n\n\n\n\n    b = list()\n    bl = list()\n    for i in range(0, cid):\n\n        A = np.ones([60,2])\n        A[:,1] = naninterp(bbfDevRegAv[:, i]) #Pchip interpolate should contain atleast two elements\n\n        lssol_ = sc.linalg.lstsq(A, naninterp(bfDevRegAv[:, i])) #returns a tuple of solution \"x\", residue and rank of matrix A; for A x = B\n        lssol = lssol_[0] \n\n        b.append(lssol[2-1])\n\n\n        A = np.ones([60,2])\n        A[:,1] = naninterp.naninterp(tsleaktotalff[:, i])\n        lssol_ = sc.linalg.lstsq(A, naninterp.naninterp(tsleaktotalf[:, i])) #returns a tuple of solution \"x\", residue and rank of matrix A; for A x = B\n        lssol = lssol_[0]\n        bl.append(lssol[2-1])\n        #Working till here 2022-10-21 1530pm\n\n    multp = npm.repmat(b, r, 1) \n    devint = bfDevRegAv * multp\n    multp = npm.repmat(bl, r, 1)\n    leakLS = tsleaktotalf * multp\n\n\n    ps = Phase_calc.Phase_calc(tsleaktotalf,tsleaktotalff)\n\n\n\n    #Compute the near true leakage\n\n    for i in range(0, cid):   \n        ftsleaktotal[:,i] = naninterp.naninterp(tsleaktotalf[:,i]) #Replaces gaps (NaN values) with an itnerpolated value in the leakage time series from once filtered fields\n        fftsleaktotal[:,i] = naninterp.naninterp(tsleaktotalff[:,i]) #replace the gaps (NaN values) with an interpolated value in leakage time series from twice filtered fields\n\n        X = sc.fft.fft(ftsleaktotal[:,i]) #take fast Fourier transform #check shape of X 2022-10-21\n        p = -ps[0,i] / r #compute the fraction of the time period by which the time series is to be shiftes\n        Y = np.exp(1j * np.pi * p * ((np.arange(r)) - r/2) / r) #compute the Conjugate-Symmetric shift \n        Z = X * Y #Apply the shift\n\n        a = sc.fft.ifft(Z) #apply inverse fft\n\n        con = np.conj(a)\n\n        s = a + con\n\n        z = s/2\n\n        leakage[:,i] = z #shifted timeseries\n\n\n        #Shift timeseriecs from once filtered fields in the direction of the time series from twice filtered fields, to later compute the amplitude ratio\n        p = ps[0,i] / r #Fraction of a time period to shift data\n        Y = np.exp(1j * np.pi * p * ((np.arange(r)) - r/2) / r) #compute the Conjugate-Symmetric shift\n        Z = X * Y\n\n        a = sc.fft.ifft(Z) #apply inverse fft\n\n        con = np.conj(a)\n\n        s = a + con\n\n        z = s/2\n\n        leakager[:,i] = z #shifted timeseries\n\n\n\n    #compute the ratio between the amplitude of the shifted leakage from once filtered fields and leakage from twice filtered fields\n    rfn = leakage/fftsleaktotal\n    rfn[(rfn) &gt;= 2] = 1\n    rfn[(rfn) &lt;= -2] = -1\n    rfn = np.sum(np.abs(rfn), axis = 0)\n    rfn=rfn/r # amplitude ratio\n\n\n    lhat = leakager * rfn #apply the amplitude ratio to the shifted leakage timeseries from the once filtered fields to get the near true leakage\n    lhat[np.isnan(FilteredTS)] = np.nan #reintroduce nan for data gaps\n    leakLS[np.isnan(FilteredTS)] = np.nan\n    RecoveredTWS = FilteredTS - leakLS - devint\n    RecoveredTWS2 = FilteredTS - lhat - devint\n\n    return RecoveredTWS, RecoveredTWS2, FilteredTS\n</code></pre>"},{"location":"core_functionality/#pyshbundle.GRACE_Data_Driven_Correction_Vishwakarma.deg_to_rad","title":"<code>deg_to_rad(deg)</code>","text":"<p>Converts angle from degree to radian</p> <p>Parameters:</p> Name Type Description Default <code>deg</code> <code>float</code> <p>Angle in degree</p> required <p>Returns:</p> Name Type Description <code>float</code> <p>Angle in Radian</p> Todo <ul> <li>Inbuilt function available in numpy module</li> </ul> Source code in <code>pyshbundle/GRACE_Data_Driven_Correction_Vishwakarma.py</code> <pre><code>def deg_to_rad(deg: float):\n    \"\"\"Converts angle from degree to radian\n\n    Args:\n        deg (float): Angle in degree\n\n    Returns:\n        float: Angle in Radian\n\n    Todo:\n        + Inbuilt function available in numpy module\n    \"\"\"\n    return deg * np.pi/180\n</code></pre>"},{"location":"core_functionality/#hydrological-applications-with-grace","title":"Hydrological Applications with GRACE","text":""},{"location":"core_functionality/#pyshbundle.basin_avg.basin_avg","title":"<code>basin_avg(data, path, c_rs, m, gs)</code>","text":"<p>Computes the TWSA time-series for a given basin shape file, using the SH data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dataset</code> <p>xarray dataset with format - {coordinates: [time, lat, lon], Data variables: [tws]}</p> required <code>path</code> <code>str</code> <p>valid path to the basin shape file with extension (.shp)</p> required <code>c_rs</code> <code>crs</code> <p>the crs into which the dataframe must be transformed (related to salem module)</p> required <code>m</code> <code>int</code> <p>number of files read</p> required <code>gs</code> <code>float</code> <p>grid size </p> required <p>Returns:</p> Name Type Description <p>xarray.Dataset: basin averaged values of TWS</p> <code>_type_</code> <p>description</p> Source code in <code>pyshbundle/basin_avg.py</code> <pre><code>def basin_avg(data, path: str, c_rs, m, gs):\n    \"\"\"Computes the TWSA time-series for a given basin shape file, using the SH data.\n\n    Args:\n        data (xarray.Dataset): xarray dataset with format - {coordinates: [time, lat, lon], Data variables: [tws]}\n        path (str): valid path to the basin shape file with extension (.shp)\n        c_rs (crs): the crs into which the dataframe must be transformed (related to salem module)\n        m (int): number of files read\n        gs (float): grid size \n\n    Returns:\n        xarray.Dataset: basin averaged values of TWS\n        _type_: _description_\n    \"\"\"\n    shdf = salem.read_shapefile(path)\n    shdf.crs\n    shdf.plot()\n    shdf_area = sum(shdf.to_crs(c_rs).area)\n    print('Area of basin in km2:',shdf_area/1e6)\n    if shdf_area &lt; 63*1e9:\n        print('Warning basin too small for GRACE data application')\n\n    tws_val = data.tws.values\n    dates = data.time\n    lat,lon = data.lat, data.lon\n    lat_shape, lon_shape = data.tws.shape[1],data.tws.shape[2]\n\n    # Calculation of area of each corresponding to  the latitudes and longitudes\n    # not sure if ';' is proper syntax may be the octave residu\n\n    deg = gs\n    x = np.linspace(0, 359+(1-deg), int(360/deg), dtype='double')\n    y = np.linspace(0, 179+(1-deg), int(180/deg), dtype='double')\n    x1 = np.linspace(1*deg, 360, int(360/deg), dtype='double')\n    y1 = np.linspace(1*deg, 180, int(180/deg), dtype='double')\n    lambd,theta = np.meshgrid(x,y)\n    lambd1,theta1 = np.meshgrid(x1,y1)\n    a = np.sin(np.deg2rad(90-theta))-np.sin(np.deg2rad(90-theta1))\n    b = (lambd1 - lambd)*np.pi/180\n\n\n    # Area of each grid (360*720)\n    area = (6378.137**2)*pow(10, 6)*(np.multiply(a, b))        # units m^2\n    tot_area = np.sum(np.sum(area))\n    tws_m = np.zeros([m, lat_shape, lon_shape])\n    for i in range(0,m,1):\n        tws_m[i, :, :] = np.multiply(tws_val[i, :, :],area)\n    ds_area_w = xr.Dataset(\n    data_vars=dict(\n        tws=([\"time\",\"lat\", \"lon\"], tws_m)\n    ),\n    coords = {\n        \"time\":dates,\n        \"lat\":lat,\n        \"lon\":lon },\n    attrs=dict(description=\"TWS Anomaly corresponding to long term (2004-2010) mean \\n lmax=96 and half radius of Gaussian filter = 500Km\"),\n    )\n\n    ds_area_w_clp= ds_area_w.salem.roi(shape=shdf)\n    # Time series for the whole basin(shapefile) in user defined range\n    alpha = ds_area_w_clp.tws.sum(dim=('lon','lat'))/shdf_area\n    fig,ax = plt.subplots(figsize=(15,5))\n    alpha.plot(ax=ax, color='b')\n    ax.set_box_aspect(0.33)\n    ax.set_title('Time series for the basin', size=15)\n    ax.set_ylabel('TWS anomaly in mm ', size=15)\n    plt.tight_layout()\n\n    return alpha, ds_area_w\n</code></pre>"},{"location":"core_functionality/#pyshbundle.tws_cal.tws_cal","title":"<code>tws_cal(data, lmax, gs, r, m)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>SC coefficients</p> required <code>lmax</code> <code>int</code> <p>maximum degree</p> required <code>gs</code> <code>float</code> <p>grid size</p> required <code>r</code> <code>_type_</code> <p>description</p> required <code>m</code> <code>_type_</code> <p>description</p> required Source code in <code>pyshbundle/tws_cal.py</code> <pre><code>def tws_cal(data, lmax: int, gs: float, r, m):\n    \"\"\"_summary_\n\n    Args:\n        data (np.ndarray): SC coefficients\n        lmax (int): maximum degree\n        gs (float): grid size\n        r (_type_): _description_\n        m (_type_): _description_\n    \"\"\"\n    SC = data\n\n    gfilter = gaussian.gaussian(lmax,r)\n    grid_y = int(180/gs)\n    grid_x = int(360/gs)\n    tws_f = np.zeros([m,grid_y,grid_x], dtype ='longdouble')\n    for i in tqdm(range(0,m,1)):\n        field = SC[i,0:lmax+1,96-lmax:96+lmax+1]\n        shfil = np.zeros([lmax+1,2*lmax+1])\n\n        for j in range(0,2*lmax+1,1):\n            shfil[:,j] = gfilter[:,0] * field[:,j]\n\n        quant = 'water' \n        grd = 'cell'\n        n = int(180/gs) \n        h = 0 \n        jflag = 0\n\n        ff = gshs.gshs(shfil, quant, grd, n, h, jflag)[0]\n\n        ff = ff*1000\n        tws_f[i,:,0:int(grid_x/2)] = ff[:,int(grid_x/2):]\n        tws_f[i,:,int(grid_x/2):] = ff[:,0:int(grid_x/2)]   \n\n    plt.imshow(tws_f[0,:,:])\n    return(tws_f)\n</code></pre>"},{"location":"faq/","title":"FAQ","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install pyshbundle, run this command in your terminal:</p> <pre><code>pip install pyshbundle\n</code></pre> <p>This is the preferred method to install pyshbundle, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>The sources for pyshbundle can be downloaded from the Github repo.</p> <p>You can clone the public repository:</p> <pre><code>git clone git://github.com/mn5hk/pyshbundle\n</code></pre>"},{"location":"license/","title":"License:","text":"<pre><code>This file is part of PySHbundle.\nPySHbundle is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.\n</code></pre>"},{"location":"load_data/","title":"Load Data","text":""},{"location":"load_data/#grace-processing-centers","title":"GRACE Processing Centers","text":"<p>There are 3 major research centers which disseminate GRACE data. These are:</p> <ul> <li>University of Texas at Austin, Center for Space Research (CSR)</li> <li>Jet Propulsion Laboratory (JPL)</li> <li>German Research Center for Geosciences (GFZ)</li> </ul>"},{"location":"load_data/#grace-data-levels","title":"GRACE Data Levels","text":"<p>GRACE data is available at different processing levels:</p> <ul> <li>Level 1: Raw satellite data<ul> <li>Level 1A: </li> <li>Level 1B:</li> </ul> </li> <li>Level 2: Spherical Harmonic Coefficients for the geopotential estimates</li> <li>Level 3: consists of mass anomalies or other standardized products such as Monthly Ocean/Land Water Equivalent Thickness, Surface-Mass Anomaly. Similarly mass concentration blocks or <code>mascons</code> are also available.</li> <li>Level 4: Time-series of catchment level hydrological estimates of TWSA</li> </ul> <p><code>PySHBundle</code> provides the capability to obtain grided Total Water Storage Anomaly(TWSA) from Level 2 data.</p>"},{"location":"load_data/#pre-processing-of-data","title":"Pre-Processing of Data","text":"<p>The purpose of this script is to, firstly read what the data source is (JPL, CSR or ITSG) read file path for GRACE L2 spherical harmonics inputs, read replacement files for tn13 and tn14 source of the SH files (JPL, ITSG or CSR)</p> <p>Replaces the certain coefficients with other given coeff.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>description</p> required <code>path_tn14</code> <code>str</code> <p>description</p> required <code>path_tn13</code> <code>str</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>pyshbundle/reader_replacer_jpl.py</code> <pre><code>def reader_replacer_jpl(path, path_tn14, path_tn13):\n    \"\"\"Replaces the certain coefficients with other given coeff.\n\n    Args:\n        path (str): _description_\n        path_tn14 (str): _description_\n        path_tn13 (str): _description_\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    file_list = os.listdir(path)\n\n    filenames = os.listdir(path)  # Names of files in folder\n    # Identify the data product source\n    if 'GFZ' in str(filenames[0]):\n        source = str('GFZ')\n    elif 'CSR' in str(filenames[0]):\n        source = str('CSR')\n    elif 'JPL' in str(filenames[0]):\n        source = str('JPL')\n    elif 'ITSG' in str(filenames[0]):\n        source = str('ITSG')\n    print(source)\n    aa = sorted(file_list, key=last_4chars)  # when does your data start at ?\n    year_start = aa[0][6:10]\n    time_axes = 0\n\n    # Counts the number of files\n    no_of_files = 0\n\n    # Empty numpy arrays to store variables\n    # Empty numpy arrays to store variables\n    line_num = 0\n    oi = 22\n    degree = [[] for x in range(oi)]\n    order = [[] for x in range(oi)]\n    clm = [[] for x in range(oi)]\n    slm = [[] for x in range(oi)]\n    slm_std = [[] for x in range(oi)]\n    clm_std = [[] for x in range(oi)]\n    start_date = [[] for x in range(oi)]\n    end_date = [[] for x in range(oi)]\n\n    # Iterate through all files\n    for file in sorted(file_list, key=last_4chars):\n        # print(file)\n        if file.endswith(\".gz\"):\n            file_name = f\"{path}/{file}\"\n            # print(file_name[-39:-32])\n\n            # Save yearwise\n            year_start, time_axes = TIME(year_start, file_name, time_axes)\n\n            # Call the function 'reader'\n            reader(file_name, line_num, degree, order, clm, slm, slm_std,\n                   clm_std, start_date, end_date, year_start, time_axes)\n            no_of_files = no_of_files + 1\n    print('Reading into clm format complete!')\n    print(\"Number of files read:\", no_of_files)\n\n    Lmax = degree[0][-1]\n    degree_order = int((Lmax+1) * (Lmax+2)/2)\n\n    # Replacement\n    print('Starting replacement')\n\n    # Replace deg 2,3\n    new_file_TN14 = path_tn14\n\n    rep_start_date, rep_end_date, c20, c30, c20_sigma, c30_sigma = [], [], [], [], [], []\n    with open(new_file_TN14, \"r\") as file:\n        stuff = file.readlines()\n        for i in range(0, len(stuff), 1):\n            line_num = str('not found')\n            if stuff[i] == str('Product:\\n'):\n                print(\"found:\", i+1)\n                line_num = i + 1\n                break\n        if type(line_num) is str:\n            print('Replacement data not found')\n        pattern = '\\s+'\n        count = 0\n        while (line_num &lt; len(stuff)):\n            split = re.split(pattern, str(stuff[line_num]))\n            c20.append(float(split[2]))\n            c30.append(float(split[5]))\n            c20_sigma.append(float(split[4])*1e-10)\n            c30_sigma.append(float(split[7])*1e-10)\n            rep_start_date.append(\n                str(julian.from_jd(float(split[0]), fmt='mjd').date()))\n            rep_end_date.append(\n                str(julian.from_jd(float(split[8]), fmt='mjd').date()))\n            line_num = line_num + 1\n            count = count + 1\n\n    # Actual replacement\n\n    index = 0\n    for year in range(0, time_axes+1, 1):\n        for y in range(0, round(len(degree[year])/int(degree_order-3)), 1):\n            while(index &lt; len(c20)):\n\n                curr_date = start_date[year][y*degree_order]\n                rep_date_cmp = rep_start_date[index]\n\n                if curr_date == rep_date_cmp:\n                    print(curr_date, rep_date_cmp, index)\n                    clm[year][y*int(degree_order-3)] = c20[index]\n                    clm_std[year][y*int(degree_order-3)] = c20_sigma[index]\n                    if math.isnan(c30[index]) == False:\n                        clm[year][y*int(degree_order-3)+3] = c30[index]\n                        clm_std[year][y*int(degree_order-3) +\n                                      3] = c30_sigma[index]\n                    index = index + 1\n                    break\n                else:\n                    index = index + 1\n    print('Degree 2,3 replacement complete!')\n\n    ''' Replace deg 1 '''\n    new_file_TN13 = path_tn13\n    rep_start_date_deg1, rep_end_date_deg1, c1m, s1m, c1m_sigma, s1m_sigma = [], [], [], [], [], []\n    with open(new_file_TN13, \"r\") as file:\n        stuff = file.readlines()\n        for i in range(0, len(stuff), 1):\n            if stuff[i] == str('end of header ===============================================================================\\n'):\n                print(\"found:\", i+1)\n                line_num = i + 1\n                break\n            else:\n                line_num = str('not found')\n        pattern = '\\s+'\n        count = 0\n        while (line_num &lt; len(stuff)):\n            split = re.split(pattern, str(stuff[line_num]))\n            c1m.append(float(split[3]))\n            s1m.append(float(split[4]))\n            c1m_sigma.append(float(split[5])*1e-10)\n            s1m_sigma.append(float(split[6])*1e-10)\n            rep_start_date_deg1.append(\n                split[7][0:4] + '-'+split[7][4:6] + '-'+split[7][6:8])\n            rep_end_date_deg1.append(\n                split[8][0:4] + '-'+split[8][4:6] + '-'+split[8][6:8])\n            line_num = line_num + 1\n            count = count + 1\n\n    # replace deg 1\n    index = 0\n    for year in range(0, time_axes+1, 1):\n        for y in range(0, int(len(degree[year])/int(degree_order-3)), 1):\n            while(index &lt; len(c1m)):\n\n                curr_date_deg1 = start_date[year][y*int(degree_order-1)]\n                rep_date_cmp_deg1 = rep_start_date_deg1[index]\n\n                if curr_date_deg1 == rep_date_cmp_deg1:\n                    print(curr_date_deg1, rep_date_cmp_deg1, index)\n                    degree[year].insert(y*int(degree_order-1), int(1))\n                    degree[year].insert(y*int(degree_order-1)+1, int(1))\n                    order[year].insert(y*int(degree_order-1), int(0))\n                    order[year].insert(y*int(degree_order-1)+1, int(1))\n                    clm[year].insert(y*int(degree_order-1), float(c1m[index]))\n                    clm[year].insert(y*int(degree_order-1) +\n                                     1, float(c1m[index+1]))\n                    slm[year].insert(y*int(degree_order-1), float(s1m[index]))\n                    slm[year].insert(y*int(degree_order-1) +\n                                     1, float(s1m[index+1]))\n                    clm_std[year].insert(\n                        y*int(degree_order-1), float(c1m_sigma[index]))\n                    clm_std[year].insert(\n                        y*int(degree_order-1)+1, float(c1m_sigma[index+1]))\n                    slm_std[year].insert(\n                        y*int(degree_order-1), float(s1m_sigma[index]))\n                    slm_std[year].insert(\n                        y*int(degree_order-1)+1, float(s1m_sigma[index+1]))\n                    start_date[year].insert(\n                        y*int(degree_order-1), rep_start_date_deg1[index])\n                    start_date[year].insert(\n                        y*int(degree_order-1)+1, rep_start_date_deg1[index+1])\n                    end_date[year].insert(\n                        y*int(degree_order-1), rep_end_date_deg1[index])\n                    end_date[year].insert(\n                        y*int(degree_order-1)+1, rep_end_date_deg1[index+1])\n                    index = index + 2\n                    break\n                else:\n                    index = index + 2\n    print('Degree 1 replacement complete!')\n\n    ''' Add degree 0 coeffs (zeros) '''\n    for year in range(0, time_axes+1, 1):\n        for y in range(0, int(len(degree[year])/int(degree_order-1)), 1):\n            degree[year].insert(y*degree_order, float(0))\n            order[year].insert(y*degree_order, float(0))\n            clm[year].insert(y*degree_order, float(0))\n            slm[year].insert(y*degree_order, float(0))\n            clm_std[year].insert(y*degree_order, float(0))\n            slm_std[year].insert(y*degree_order, float(0))\n            start_date[year].insert(\n                y*degree_order, start_date[year][y*degree_order+1])\n            end_date[year].insert(\n                y*degree_order, end_date[year][y*degree_order+1])\n\n    ''' Save everything in a list '''\n    saved_as_num = [degree, order, clm, slm,\n                    clm_std, slm_std, start_date, end_date]\n\n    ''' Number of years '''\n    beta = np.zeros(len(start_date))\n    sum = 0\n    for x in range(0, time_axes+1, 1):\n        beta[x] = round(len(start_date[x])/degree_order)\n        sum = sum + beta[x]\n\n    ''' Finding the dates for time bounds of data '''\n    dates_start, dates_end = [], []\n    for i in range(0, time_axes+1, 1):\n        j = 0\n        while j &lt; beta[i]:\n            dates_start.append(str(start_date[i][j*degree_order]))\n            dates_end.append(str(end_date[i][j*degree_order]))\n            j = j + 1\n    print(\"Number of months of data in each year starting\", dates_start[0],\n          \"&amp; ending\", dates_end[-1], beta)\n\n    # import pickle\n    # with open(\"/home/wslvivek/Desktop/level2/pysh_v2/output/saved_as_num\",\"wb\") as pk:\n    #     pickle.dump(saved_as_num, pk)\n\n    return saved_as_num, dates_start, dates_end, no_of_files\n</code></pre> Source code in <code>pyshbundle/reader_replacer_csr.py</code> <pre><code>def reader_replacer_csr(path, path_tn14, path_tn13):\n\n    file_list = os.listdir(path)\n\n    filenames = os.listdir(path) #Names of files in folder\n    # Identify the data product source\n    if 'GFZ' in str(filenames[1]):\n        source = str('GFZ')  \n    elif 'CSR' in str(filenames[1]):\n        source = str('CSR')\n    elif 'JPL' in str(filenames[1]):\n        source = str('JPL')\n    elif 'ITSG' in str(filenames[0]):\n        source = str('ITSG')\n    print(source)\n    aa = sorted(file_list, key = last_4chars)  #when does your data start at ?\n    year_start = aa[0][6:10]\n    time_axes = 0\n\n    # Counts the number of files\n    no_of_files = 0\n\n    # Empty numpy arrays to store variables\n    # Empty numpy arrays to store variables\n    line_num = 0\n    oi = 22\n    degree = [[] for x in range(oi)]\n    order = [[] for x in range(oi)]\n    clm = [[] for x in range(oi)]\n    slm = [[] for x in range(oi)]\n    clm_std = [[] for x in range(oi)]\n    slm_std = [[] for x in range(oi)]\n    start_date = [[] for x in range(oi)]\n    end_date = [[] for x in range(oi)]\n\n    # Iterate through all files\n    for file in sorted(file_list, key = last_4chars):\n        #print(file)\n        if file.endswith(\".gz\"):\n            file_name = f\"{path}/{file}\"\n            # print(file_name[-39:-32])\n\n            # Save yearwise\n            year_start, time_axes = TIME(year_start,file_name,time_axes)\n\n            # Call the function 'reader'\n            reader(file_name,line_num,degree,order,clm,slm,clm_std,slm_std,start_date,end_date,year_start,time_axes)\n            no_of_files = no_of_files + 1\n\n    print('Reading into klm format complete!')\n    print(\"Number of files read:\", no_of_files)\n\n    Lmax=degree[0][-1]\n    degree_order=int((Lmax+1)*(Lmax+2)/2)\n    #''' Replacement '''\n    print('Starting replacement')\n   # ''' Replace deg 2,3 '''\n    new_file_TN14 = path_tn14\n    rep_start_date, rep_end_date, c20, c30, c20_sigma, c30_sigma = [], [], [], [], [], []\n    with open(new_file_TN14,\"r\") as file:\n        stuff = file.readlines()\n        for i in range(0,len(stuff),1):\n            line_num = str('not found')\n            if  stuff[i] == str('Product:\\n'):\n                print(\"found:\",i+1)\n                line_num = i + 1\n                break\n        if type(line_num) is str:\n            print('Replacement data not found')\n        pattern = '\\s+'\n        count = 0\n        while (line_num&lt;len(stuff)):\n            split = re.split(pattern, str(stuff[line_num]))\n            c20.append( float(split [2]) )\n            c30.append( float(split[5]) )\n            c20_sigma.append(float(split[4])*1e-10)\n            c30_sigma.append(float(split[7])*1e-10)\n            rep_start_date.append(str(julian.from_jd(float(split[0]), fmt='mjd').date()))\n            rep_end_date.append(str(julian.from_jd(float(split[8]), fmt='mjd').date()))\n            line_num = line_num + 1\n            count = count + 1\n\n    # Actual replacement    \n\n    index = 0\n    margin=datetime.timedelta(days = 5)\n    for year in range(0,time_axes+1,1):\n        # index = 0\n        for y in range(0,round(len(clm[year])/degree_order),1):    \n            while(index&lt;len(c20)):\n\n                curr_date = datetime.datetime.strptime(start_date[year][y*degree_order], '%Y-%m-%d')\n                rep_date_cmp = datetime.datetime.strptime(rep_start_date[index], '%Y-%m-%d')\n\n                if  rep_date_cmp-margin &lt;= curr_date &lt;= rep_date_cmp+margin:\n                    print(curr_date, rep_date_cmp, index)\n                    clm[year][y*degree_order+2] = c20[index]\n                    clm_std[year][y*degree_order+2] = c20_sigma[index]\n                    index = index +1\n                    if math.isnan(c30[index]) == False:\n                        clm[year][y*degree_order+3] = c30[index]\n                        # NOTE: rectified from slm_dev -&gt; clm_dev\n                        clm_std[year][y*degree_order+3] = c30_sigma[index]\n                    break\n                else:   \n                    index = index +1                           \n    print('Degree 2,3 replacement complete!')\n\n    #''' Replace deg 1 '''\n    new_file_TN13 = path_tn13  \n    rep_start_date_deg1, rep_end_date_deg1, c1m, s1m, c1m_sigma, s1m_sigma = [], [], [], [], [], []\n    with open(new_file_TN13,\"r\") as file:\n        stuff = file.readlines()\n        for i in range(0,len(stuff),1):\n            if  stuff[i] == str('end of header ===============================================================================\\n'):\n                print(\"found:\",i+1)\n                line_num = i + 1\n                break\n            else:\n                line_num = str('not found')\n        pattern = '\\s+'\n        count = 0\n        while (line_num&lt;len(stuff)):\n            split = re.split(pattern, str(stuff[line_num]))\n            c1m.append( float(split [3]) )\n            s1m.append( float(split[4]) )\n            c1m_sigma.append( float(split[5])*1e-10)\n            s1m_sigma.append( float(split[6])*1e-10)\n            rep_start_date_deg1.append(split[7][0:4] +'-'+split[7][4:6] +'-'+split[7][6:8])\n            rep_end_date_deg1.append(split[8][0:4] +'-'+split[8][4:6] +'-'+split[8][6:8])\n            line_num = line_num + 1\n            count = count + 1 \n\n    # replace deg 1   \n    index = 0\n    Lmax = degree[0][-1]\n    margin_deg1=datetime.timedelta(days = 5)\n    for year in range(0,time_axes+1,1):\n        for y in range(0,int(len(clm[year])/degree_order),1):    \n            while(index&lt;len(c1m)):\n                curr_date_deg1 = datetime.datetime.strptime(start_date[year][y*degree_order], '%Y-%m-%d')\n                rep_date_cmp_deg1 = datetime.datetime.strptime(rep_start_date_deg1[index], '%Y-%m-%d')\n\n                if  rep_date_cmp_deg1-margin_deg1 &lt;= curr_date_deg1 &lt;= rep_date_cmp_deg1+margin_deg1:\n                    print(curr_date_deg1, rep_date_cmp_deg1, index)\n                    # degree[year][y*degree_order+1] = int(1)\n                    # degree[year][y*degree_order+1+Lmax] = int(1)\n                    # order[year][y*degree_order+1] = int(0)\n                    # order[year][y*degree_order+1+Lmax] = int(1)\n                    clm[year][y*degree_order+1] = c1m[index]\n                    clm[year][y*degree_order+1+Lmax] = c1m[index+1]\n                    slm[year][y*degree_order+1] = s1m[index]\n                    slm[year][y*degree_order+1+Lmax] = s1m[index+1]\n                    clm_std[year][y*degree_order+1] = c1m_sigma[index]\n                    clm_std[year][y*degree_order+1+Lmax] = c1m_sigma[index+1]\n                    slm_std[year][y*degree_order+1] = s1m_sigma[index]\n                    slm_std[year][y*degree_order+1+Lmax] = s1m_sigma[index+1]\n\n                    index = index +2\n                    break\n                else:\n                    index = index +2\n    print('Degree 1 replacement complete!') \n\n    #''' Save everything in a list '''\n    saved_as_num=[degree,order,clm,slm,clm_std,slm_std,start_date,end_date]\n\n    #''' Number of years '''\n    beta = np.zeros(len(start_date))\n    sum = 0\n    for x in range(0,time_axes+1,1):\n        beta[x] = (len(start_date[x])/degree_order)\n        sum = sum + len(start_date[x])/degree_order \n\n    #''' Finding the dates dates_csrfor time bounds of data '''\n    dates_start, dates_end = [],[] \n    for i in range(0,time_axes+1,1):\n        j = 0\n        while j &lt; beta[i]:\n            dates_start.append(str(start_date[i][j*degree_order]))\n            dates_end.append(str(end_date[i][j*degree_order]))\n            j = j + 1\n    print(\"Number of months of data in each year starting\", dates_start[0], \\\n          \"&amp; ending\", dates_end[-1], beta)   \n\n    #import pickle\n    #with open(\"/home/wslvivek/Desktop/level2/pysh_v2/output/saved_as_num\",\"wb\") as pk:\n    #    pickle.dump(saved_as_num, pk)\n    return saved_as_num, dates_start,dates_end, no_of_files\n</code></pre> <p>summary</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>_type_</code> <p>description</p> required <code>path_tn14</code> <code>_type_</code> <p>description</p> required <code>path_tn13</code> <code>_type_</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>pyshbundle/reader_replacer_itsg.py</code> <pre><code>def reader_replacer_itsg(path, path_tn14, path_tn13):\n    \"\"\"_summary_\n\n    Args:\n        path (_type_): _description_\n        path_tn14 (_type_): _description_\n        path_tn13 (_type_): _description_\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    file_list = os.listdir(path)\n\n    filenames = os.listdir(path)       #Names of files in folder    \n    # Identify the data product source\n    if 'GFZ' in str(filenames[0]):\n        source = str('GFZ')\n    elif 'CSR' in str(filenames[0]):\n        source = str('CSR')\n    elif 'JPL' in str(filenames[0]):\n        source = str('JPL')\n    elif 'ITSG' in str(filenames[0]):\n        source = str('ITSG')\n    print(source)\n    aa = sorted(file_list, key = last_4chars) #when does your data start at ?\n    year_start = aa[0][-11:-7]\n    time_axes = 0\n\n    # Counts the number of files\n    no_of_files = 0\n\n    # Empty numpy arrays to store variables\n    # Empty numpy arrays to store variables\n    line_num = 0\n    oi = 22\n    degree = [[] for x in range(oi)]\n    order = [[] for x in range(oi)]\n    clm = [[] for x in range(oi)]\n    slm = [[] for x in range(oi)]\n    clm_std = [[] for x in range(oi)]\n    slm_std = [[] for x in range(oi)]\n    start_date = [[] for x in range(oi)]\n\n    # Iterate through all files\n    for file in sorted(file_list, key = last_4chars):\n        #print(file)\n        if file.endswith(\".gfc\"):\n            file_name = f\"{path}/{file}\"\n            #print(file_name[-39:-32])\n\n            # Save yearwise\n            year_start, time_axes = TIME(year_start,file_name,time_axes)\n\n            # Call the function 'reader'\n            reader(file_name,line_num,degree,order,clm,slm,clm_std,slm_std,start_date,year_start,time_axes)\n            no_of_files = no_of_files + 1\n    print('Reading into clm format complete!')\n    print(\"Number of files read:\", no_of_files)\n\n    Lmax=degree[0][-1]\n    degree_order=int((Lmax+1)*(Lmax+2)/2)\n\n    ''' Replacement '''\n\n    print('Starting replacement')\n    ''' Replace deg 2,3 '''\n    new_file_TN14 = path_tn14\n\n    rep_start_date, rep_end_date, c20, c30, c20_sigma, c30_sigma = [], [], [], [], [], []\n    with open(new_file_TN14,\"r\") as file:\n        stuff = file.readlines()\n        for i in range(0,len(stuff),1):\n            line_num = str('not found')\n            if  stuff[i] == str('Product:\\n'):\n                print(\"found:\",i+1)\n                line_num = i + 1\n                break\n        if type(line_num) is str:\n            print('Replacement data not found')\n        pattern = '\\s+'\n        count = 0\n        while (line_num&lt;len(stuff)):\n            split = re.split(pattern, str(stuff[line_num]))\n            c20.append( float(split [2]) )\n            c30.append( float(split[5]) )\n            c20_sigma.append(float(split[4])*1e-10)\n            c30_sigma.append(float(split[7])*1e-10)\n            rep_start_date.append(str(julian.from_jd(float(split[0]), fmt='mjd').date()))\n            rep_end_date.append(str(julian.from_jd(float(split[8]), fmt='mjd').date()))\n            line_num = line_num + 1\n            count = count + 1\n\n    # Actual replacement    \n\n    index = 0\n    margin=datetime.timedelta(days = 23)\n    for year in range(0,time_axes+1,1):\n        for y in range(0,int(len(clm[year])/degree_order),1):    \n            while(index&lt;len(c20)):\n\n                curr_date = datetime.datetime.strptime(start_date[year][y*degree_order], '%Y-%m')\n                rep_date_cmp = datetime.datetime.strptime(rep_start_date[index], '%Y-%m-%d')\n\n                if rep_date_cmp-margin &lt;= curr_date &lt;= rep_date_cmp+margin:\n                    print(f\"Data date - {curr_date}, replacemebt date (tn-14) = {rep_date_cmp}\")\n                    clm[year][y*degree_order+3] = c20[index]\n                    clm_std[year][y*degree_order+3] = c20_sigma[index]\n                    if math.isnan(c30[index]) == False:\n                        clm[year][y*degree_order+6] = c30[index]\n                        clm_std[year][y*degree_order+6] = c30_sigma[index]\n                    index= index + 1\n                    break\n                else:   \n                    index = index +1\n\n    print('Degree 2,3 replacement complete!')\n\n\n    ''' Replace deg 1 '''\n    new_file_TN13 = path_tn13\n    rep_start_date_deg1, rep_end_date_deg1, c1m, s1m, c1m_sigma, s1m_sigma = [], [], [], [], [], []\n    with open(new_file_TN13,\"r\") as file:\n        stuff = file.readlines()\n        for i in range(0,len(stuff),1):\n            if  stuff[i] == str('end of header ===============================================================================\\n'):\n                print(\"found:\",i+1)\n                line_num = i + 1\n                break\n            else:\n                line_num = str('not found')\n        pattern = '\\s+'\n        count = 0\n        while (line_num&lt;len(stuff)):\n            split = re.split(pattern, str(stuff[line_num]))\n            c1m.append( float(split [3]) )\n            s1m.append( float(split[4]) )\n            c1m_sigma.append( float(split [5]) )\n            s1m_sigma.append( float(split[6]) )\n            rep_start_date_deg1.append(split[7][0:4] +'-'+split[7][4:6] +'-'+split[7][6:8])\n            rep_end_date_deg1.append(split[8][0:4] +'-'+split[8][4:6] +'-'+split[8][6:8])\n            line_num = line_num + 1\n            count = count + 1 \n\n    # replace deg 1   \n    index = 0\n    margin=datetime.timedelta(days = 23)\n    for year in range(0,time_axes+1,1):\n        for y in range(0,int(len(clm[year])/degree_order),1):    \n            while(index&lt;len(c1m)):\n\n                curr_date = datetime.datetime.strptime(start_date[year][y*degree_order], '%Y-%m')\n                rep_date_cmp_deg1 = datetime.datetime.strptime(rep_start_date_deg1[index], '%Y-%m-%d')\n\n                if rep_date_cmp_deg1-margin &lt;= curr_date &lt;=rep_date_cmp_deg1+margin:\n                    print(f\"Data date - {curr_date}, replacemebt date (tn-13) = {rep_date_cmp_deg1}\")\n                    degree[year][y*degree_order+1]=int(0)\n                    degree[year][y*degree_order+2]=int(1)\n                    order[year][y*degree_order+1]=int(0)\n                    order[year][y*degree_order+2]=int(1)\n                    clm[year][y*degree_order+1]=float(c1m[index])\n                    clm[year][y*degree_order+2]=float(c1m[index+1])\n                    slm[year][y*degree_order+1]=float(s1m[index])\n                    slm[year][y*degree_order+2]=float(s1m[index+1])\n                    clm_std[year][y*degree_order+1]=float(c1m_sigma[index])\n                    clm_std[year][y*degree_order+2]=float(c1m_sigma[index+1])\n                    slm_std[year][y*degree_order+1]=float(s1m_sigma[index])\n                    slm_std[year][y*degree_order+2]=float(s1m_sigma[index+1])\n                    start_date[year][y*degree_order+1]=rep_start_date_deg1[index]\n                    start_date[year][y*degree_order+2]=rep_start_date_deg1[index+1]\n                    index = index +2\n                    break\n                else:\n                    index = index +2\n    print('Degree 1 replacement complete!')\n\n    ''' Save everything in a list '''\n    saved_as_num=[degree,order,clm,slm,clm_std,slm_std,start_date]\n    # import pickle\n    # with open(\"/home/wslvivek/Desktop/level2/pysh_v2/output/saved_as_num\",\"wb\") as pk:\n    #     pickle.dump(saved_as_num, pk)\n\n\n    ''' Number of years '''\n    beta = np.zeros(len(start_date))\n    sum = 0\n    for x in range(0,time_axes+1,1):\n        beta[x] = round(len(start_date[x])/degree_order)\n        sum = sum + beta[x]\n\n    ''' Finding the dates for time bounds of data '''\n    dates_start = []\n    for i in range(0,time_axes+1,1):\n        j = 0\n        while j &lt; beta[i]:\n            dates_start.append(str(start_date[i][j*degree_order]))\n            # dates_end.append(str(end_date[i][j*int(degree_order-3)]))\n            j = j + 1\n    print(\"Number of months of data in each year starting\", dates_start[0], beta) #dates_end[-1], beta)       \n    return saved_as_num, dates_start, no_of_files\n</code></pre> <p>Function to read files &amp; extract data</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>_type_</code> <p>description</p> required <code>line_num</code> <code>_type_</code> <p>description</p> required <code>degree</code> <code>_type_</code> <p>description</p> required <code>order</code> <code>_type_</code> <p>description</p> required <code>clm</code> <code>_type_</code> <p>description</p> required <code>slm</code> <code>_type_</code> <p>description</p> required <code>delta_clm</code> <code>_type_</code> <p>description</p> required <code>delta_slm</code> <code>_type_</code> <p>description</p> required <code>start_date</code> <code>_type_</code> <p>description</p> required <code>end_date</code> <code>_type_</code> <p>description</p> required <code>year_start</code> <code>_type_</code> <p>description</p> required <code>time_axes</code> <code>_type_</code> <p>description</p> required Source code in <code>pyshbundle/reader_replacer.py</code> <pre><code>def reader(file_name: str,line_num, degree: int, order: int, clm,slm,delta_clm,delta_slm,start_date,end_date,year_start,time_axes):\n    \"\"\"Function to read files &amp; extract data\n\n    Args:\n        file_name (_type_): _description_\n        line_num (_type_): _description_\n        degree (_type_): _description_\n        order (_type_): _description_\n        clm (_type_): _description_\n        slm (_type_): _description_\n        delta_clm (_type_): _description_\n        delta_slm (_type_): _description_\n        start_date (_type_): _description_\n        end_date (_type_): _description_\n        year_start (_type_): _description_\n        time_axes (_type_): _description_\n    \"\"\"\n    with gzip.open(file_name,\"r\") as file:\n        stuff = file.readlines()\n        stuff\n        for i in range (0,len(stuff),1):\n            #print(str(line))\n            if str(stuff[i]) == str( b'# End of YAML header\\n',):\n                #print(\"found:\",i+1)\n                line_num = i+1                                                 #Line number of starting line of data\n                break\n        pattern = '\\s+'                                                        #Delimiter for splitting                                                          \n        while(line_num&lt;len(stuff)):\n            split = re.split(  pattern, str(stuff[line_num]))                  #split wordwise with Regex\n            degree[time_axes].append(  int(split[1])  )\n            order[time_axes].append( int(split [2])    )\n            clm[time_axes].append( float(split [3])    )\n            slm[time_axes].append( float(split [4])    )\n            delta_clm[time_axes].append( float(split [5])    )\n            delta_slm[time_axes].append(  float(split[6])    )\n            start_date[time_axes].append(  split[7][0:4]+'-'+split[7][4:6]+'-'+split[7][6:8]  )\n            end_date[time_axes].append(  split[8][0:4]+'-'+split[8][4:6]+'-'+split[8][6:8]  )\n            line_num = line_num + 1\n</code></pre>"},{"location":"load_data/#pyshbundle.read_GRACE_SH_paths.read_GRACE_SH_paths","title":"<code>read_GRACE_SH_paths(use_sample_files=0)</code>","text":"<p>Returns path of data files, path of tn13 and path of tn14 replacement files</p> <p>Parameters:</p> Name Type Description Default <code>use_sample_files</code> <code>int</code> <p>description. Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>pyshbundle/read_GRACE_SH_paths.py</code> <pre><code>def read_GRACE_SH_paths(use_sample_files = 0):\n    \"\"\"Returns path of data files, path of tn13 and path of tn14 replacement files\n\n    Args:\n        use_sample_files (int, optional): _description_. Defaults to 0.\n\n    Raises:\n        Exception: _description_\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n\n    print(\"This program supports working with GRACE L2 Spherical harmonics data from the following centers: CSR, JPL and ITSG\")\n    print(\"Instructions to download data may be referred to in https://github.com/mn5hk/pyshbundle/blob/main/docs/index.md#how-to-download-data\")\n    source = str(input(\"Enter the source of L2 SH coeffs code(jpl, csr, gfz): \"))\n\n    if use_sample_files ==1:\n\n        print(\"You have chosen to use sample replacement files.\")\n        print(\"The replacement files for the TN13 and TN14 parameters have been preloaded into the program\")\n        print(\"Due to the size of the GRACE SH files, these have not been preloaded into the program\")\n        print(\"You may download the GRACE SH L2 files from the link below. Please ensure to download the files as per your selection of source in the prior step\")\n        print(\"Download sample files from: https://github.com/mn5hk/pyshbundle/tree/main/sample_input_data\")\n    path_sh = str(input(\"Enter the path to the folder with SH L2 data\"))\n\n\n    if str.upper(source) == 'JPL':\n        if use_sample_files == 1:\n            path_tn13 = pkg_resources.resource_filename('pyshbundle', 'data/sample_JPL_TN_files/TN-13_GEOC_JPL_RL06.txt')\n            path_tn14 = pkg_resources.resource_filename('pyshbundle', 'data/sample_JPL_TN_files/TN-14_C30_C20_GSFC_SLR.txt')\n            print(\"Successfully loaded preloaded TN13 and TN14 replacement files for JPL\")\n        else:\n            path_tn13 = str(input(\"Enter the path to the file for tn13 replacement in .txt format\"))\n            path_tn14 = str(input(\"Enter the path to the file for tn14 replacement in .txt format\"))\n            print(\"Successfully loaded TN13 and TN14 replacement files for JPL\")\n\n    elif str.upper(source) == 'CSR':\n        if use_sample_files == 1:\n            path_tn13 = pkg_resources.resource_filename('pyshbundle', 'data/sample_CSR_TN_files/TN-14_C30_C20_SLR_GSFC.txt')\n            path_tn14 = pkg_resources.resource_filename('pyshbundle', 'data/sample_CSR_TN_files/TN-13_GEOC_CSR_RL06.1.txt')\n            print(\"Successfully loaded preloaded TN13 and TN14 replacement files for CSR\")\n        else:\n            path_tn13 = str(input(\"Enter the path to the file for tn13 replacement in .txt format\"))\n            path_tn14 = str(input(\"Enter the path to the file for tn14 replacement in .txt format\"))\n            print(\"Successfully loaded TN13 and TN14 replacement files for CSR\")\n\n    elif str.upper(source) == 'ITSG':\n        if use_sample_files == 1:\n            path_tn13 = pkg_resources.resource_filename('pyshbundle', 'data/sample_ITSG_TN_files/TN-13_GEOC_CSR_RL06.1.txt')\n            path_tn14 = pkg_resources.resource_filename('pyshbundle', 'data/sample_ITSG_TN_files/TN-14_C30_C20_SLR_GSFC.txt')\n            print(\"Successfully loaded preloaded TN13 and TN14 replacement files for ITSG\")\n        else:\n            path_tn13 = str(input(\"Enter the path to the file for tn13 replacement in .txt format\"))\n            path_tn14 = str(input(\"Enter the path to the file for tn14 replacement in .txt format\"))\n            print(\"Successfully loaded TN13 and TN14 replacement files for ITSG\")\n    else:\n        raise Exception(\"Source selection is incorrect. Please select between JPL, CSR or gfz\")\n\n    return path_sh, path_tn13, path_tn14, source\n</code></pre>"},{"location":"load_data/#computing-ling-term-mean","title":"Computing Ling Term Mean","text":"<p>The purpose of this script is to, load longterm mean for our GRACE SH data</p> <p>For this, we need to input the GRACE data source as well as the path to the longterm mean values Data source may be CSR, JPL or ITSG.</p> <p>For RL06, example data have been provided within the package. In case this option is chosen, the program directly returns the longterm mean values.</p> <p>Returns the long_mean path</p>"},{"location":"load_data/#pyshbundle.load_longterm_mean.load_longterm_mean","title":"<code>load_longterm_mean(source='', use_sample_mean=0)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>description. Defaults to \"\".</p> <code>''</code> <code>use_sample_mean</code> <code>int</code> <p>description. Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p> <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Todo <ul> <li>Not sure if using \"source = ''\" is all right</li> <li>instead of base eception is can be ValueError</li> </ul> Source code in <code>pyshbundle/load_longterm_mean.py</code> <pre><code>def load_longterm_mean(source = \"\", use_sample_mean = 0):\n    \"\"\"_summary_\n\n    Args:\n        source (str, optional): _description_. Defaults to \"\".\n        use_sample_mean (int, optional): _description_. Defaults to 0.\n\n    Raises:\n        Exception: _description_\n\n    Returns:\n        _type_: _description_\n\n    Todo:\n        + Not sure if using \"source = ''\" is all right\n        + instead of base eception is can be ValueError\n    \"\"\"\n    if use_sample_mean == 1:\n        print(\"Loading preloaded RL06 long term mean values\")\n        print(\"Please ensure that your data is RL06 \\nIf not, please manually input long term mean by setting use_sample_mean = 0\")\n\n        if str.upper(source) == 'CSR':\n            long_mean = pkg_resources.resource_filename('pyshbundle', 'data/RL06_long_mean/SH_long_mean_csr.npy')\n        elif str.upper(source) == 'JPL':\n            long_mean = pkg_resources.resource_filename('pyshbundle', 'data/RL06_long_mean/SH_long_mean_itsg.npy')\n        elif str.upper(source) == 'ITSG':\n            long_mean = pkg_resources.resource_filename('pyshbundle', 'data/RL06_long_mean/SH_long_mean_jpl.npy')\n        else:\n            raise Exception(\"Incorrect selection of source\")\n        print(\"Successfully loaded preloaded longterm means\")\n    else:\n        print(\"Please download and provide the longterm GRACE SH mean values\")\n        print(\"Instructions to download the longterm GRACE SH mean values may be referred to in https://github.com/mn5hk/pyshbundle/blob/main/docs/index.md#how-to-download-data\")\n        long_mean = str(input(\"Enter the longterm mean for the SH values in the numpy (.npy) format\"))\n        print(\"Successfully loaded path to long term mean:\", long_mean)\n\n    return long_mean\n</code></pre>"},{"location":"load_data/#physical-and-geodetic-constants","title":"Physical and Geodetic Constants","text":"<p>This script contains some of the major relavant Physical and Geodetic(GRS80) constants:</p> <ul> <li><code>clight</code> speed of light - \\(2.99792458e+8\\) \\(m/s\\)</li> <li><code>G</code> Gravitational constant- \\(6.67259e-11\\) $\frac{m^3} {kg \\cdot s^2}$</li> <li> <p><code>au</code> astronomical unit - \\(149.597870691e+9\\) \\(m\\)</p> </li> <li> <p><code>ae</code> semi-major axis of ellipsoid <code>GRS 80</code>- \\(6378137\\) m</p> </li> <li><code>GM</code> geocentric grav. constant <code>GRS 80</code>- \\(3.986005e+14\\) $\frac{m^3}{s^2}$</li> <li><code>J2</code> earth's dynamic form factor <code>GRS 80</code> - \\(1.08263e-3\\) [unitless C20 unnormalized coefficient]</li> <li> <p><code>Omega</code> mean ang. velocity <code>GRS 80</code> - $7.292115e-5 $\frac{rad}{s}$</p> </li> <li> <p><code>flat</code> flattening - $\frac{1}{298.257222101}$</p> </li> </ul>"},{"location":"pyshbundle/","title":"Reference Mannual - PySHBundle","text":"<p>The module codes can be categorized into four categories:</p> <ul> <li>load data</li> <li>convert data formats</li> <li>core functionality</li> <li>auxillary codes</li> </ul> <p></p> <p>Navigate the Reference Manual based on the following schematic</p>"},{"location":"usage/","title":"Usage","text":"<p>To use pyshbundle in a project:</p> <pre><code>import pyshbundle\n</code></pre>"}]}